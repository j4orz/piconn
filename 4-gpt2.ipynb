{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "model loaded to cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model: gpt2\n",
    "- (Vaswani et al. 2017 https://arxiv.org/abs/1706.03762)\n",
    "- (Radford et al. 2019 https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- (Brown et al. 2020 https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "pre-gpt       ->    gpt2                                 URL\n",
    "-----------------------------------------------------------------------------------------\n",
    "- ReLU        ->    GeLU: (Hendrycks, Gimpel 2016)       https://arxiv.org/abs/1606.08415\n",
    "- BatchNorm   ->    LayerNorm: (Ba et al. 2016)          https://arxiv.org/abs/1607.06450\n",
    "- N/A         ->    Residuals: (He et al. 2015)          https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "\n",
    "Dimension key:\n",
    "\n",
    "# windows\n",
    "B: batch size\n",
    "T: sequence length\n",
    "\n",
    "# input/output\n",
    "V: vocabulary size\n",
    "D: model dimension (n_embd)\n",
    "\n",
    "# attention\n",
    "N: number of transformer blocks (n_layer)\n",
    "H: number of attention heads in a layer (n_head)\n",
    "K: size of each attention key or value (n_k)\n",
    "\"\"\"\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # windows: B, T\n",
    "    batch_size: int = -1   # B\n",
    "    block_size: int = 1024  # T\n",
    "    # input/output:  V, D\n",
    "    vocab_size: int = 50257  # V (256 bytes + 50,000 BPE merges + 1 <|endoftext|> token)\n",
    "    n_embd: int = 768      # D\n",
    "    # attn: NH\n",
    "    n_layer: int = 12      # N\n",
    "    n_head: int = 12       # H\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        T, D, H = config.block_size, config.n_embd, config.n_head\n",
    "        assert D % H == 0\n",
    "\n",
    "        self.H = H\n",
    "\n",
    "        self.c_attn = nn.Linear(D, 3 * D)\n",
    "        self.c_proj = nn.Linear(D, D)\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(T, T)).view(1, 1, T, T)) # tril -> bias for HF\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        B,T,D = X_BTD.shape\n",
    "        H = self.H\n",
    "        # 1. project to learned QKV subspaces Q=WqX, K=WkX, V=WvX\n",
    "        Wq_DK, Wk_DK, Wv_DK = self.c_attn(X_BTD).split(D, dim=2)\n",
    "        Q_BHTK, K_BHTK, V_BHTK = Wq_DK.view(B, T, H, D // H).transpose(1, 2), Wk_DK.view(B, T, H, D // H).transpose(1, 2), Wv_DK.view(B, T, H, D // H).transpose(1, 2)\n",
    "\n",
    "        # 2. evaluate scores A(QKV) = softmax(QK^T/sqrt(d_k))V\n",
    "        A_BHTT = Q_BHTK @ K_BHTK.transpose(-2, -1) * (1.0 / math.sqrt(K_BHTK.size(-1)))\n",
    "        A_BHTT = A_BHTT.masked_fill(self.bias[:, :, :T, :T]==0, float('-inf'))\n",
    "        A_BHTT = F.softmax(A_BHTT, dim=-1) # todo, when dim=-1?\n",
    "\n",
    "        # 3. contextualize the embeddings\n",
    "        S_BHTD = A_BHTT @ V_BHTK\n",
    "        S_BTD = S_BHTD.transpose(1, 2).contiguous().view(B, T, D) # performs cat\n",
    "        S_BTD = self.c_proj(S_BTD)\n",
    "\n",
    "        return S_BTD\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D = config.n_embd\n",
    "        self.c_fc = nn.Linear(D, 4*D) # projecting up to extract features from context embeddings\n",
    "        self.gelu = nn.GELU(approximate='tanh') # (Hendrycks et al. https://arxiv.org/abs/1606.08415)\n",
    "        self.c_proj = nn.Linear(4*D, D) # projecting back down to residual pathway\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        X_BT4D = self.c_fc(X_BTD)\n",
    "        X_BT4D = self.gelu(X_BT4D)\n",
    "        X_BTD = self.c_proj(X_BT4D)\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class LayerNorm(nn.Module): # manual inefficient LayerNorm implementation\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward():\n",
    "#         # ...\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D, H = config.n_embd, config.n_head\n",
    "        self.ln_1 = nn.LayerNorm(D)\n",
    "        self.attn = MHA(config)\n",
    "        self.mlp = FFN(config) # .mlp for HF\n",
    "        self.ln_2 = nn.LayerNorm(D)\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        # residuals:\n",
    "        # - (He et al. 2015 https://arxiv.org/abs/1512.03385)\n",
    "        # - (Elhage et al. 2021 https://transformer-circuits.pub/2021/framework/index.html)\n",
    "        X_BTD = X_BTD + self.attn(self.ln_1(X_BTD))\n",
    "        X_BTD = X_BTD + self.mlp(self.ln_2(X_BTD))\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        B, T = config.batch_size, config.block_size\n",
    "        V, D = config.vocab_size, config.n_embd\n",
    "        N, H = config.n_layer, config.n_head\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(V, D), # Wt\n",
    "            wpe = nn.Embedding(T, D), # Wp\n",
    "            h = nn.ModuleList([Block(config) for _ in range(N)]),\n",
    "            ln_f = nn.LayerNorm(D),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(D, V, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight # weight sharing (40m/120m ~30% save)\n",
    "        self.apply(self._init_weights) # weight init (roughly Xavier)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std=0.02 # default std for nn.Linear() and nn.Embedding(). nn.LayerNorm defaults are OK\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'GPT2_SCALE_INIT'):\n",
    "                std = (2 * self.config.n_layer ** -0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias) # instead of default of unit gaussian\n",
    "\n",
    "        if isinstance(module, nn.Linear) or isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std) # ~ 1/sqrt(D={768, 1024, 1280, 1600}) (Xavier init)\n",
    "\n",
    "    def forward(self, X_BT, Y_BT=None): # Some(Y_BT) => training, None => inference\n",
    "        B, T = X_BT.shape\n",
    "        # 1. embedding: BTD\n",
    "        Xtok_BTD = self.transformer.wte(X_BT)\n",
    "        Xpos_TD = self.transformer.wpe(torch.arange(0, T, dtype=torch.long, device=X_BT.device))\n",
    "        X_BTD = Xtok_BTD + Xpos_TD\n",
    "        # 2. N transformer blocks: Nx(BTD -> BTK -> BTD)\n",
    "        for h in self.transformer.h:\n",
    "            X_BTD = h(X_BTD)\n",
    "        # 3. logits: BTD -> BTV\n",
    "        X_BTD = self.transformer.ln_f(X_BTD)\n",
    "        logits_BTV = self.lm_head(X_BTD)\n",
    "        loss = None\n",
    "\n",
    "        if Y_BT is not None:\n",
    "            V = self.config.vocab_size\n",
    "            loss = F.cross_entropy(logits_BTV.view(B*T, V), Y_BT.view(B*T)) # reshape for .cross_entropy()\n",
    "        return logits_BTV, loss\n",
    " \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "\n",
    "\n",
    "\n",
    "        # 1. model init\n",
    "        model_hf, model = GPT2LMHeadModel.from_pretrained(model_type), GPT(GPTConfig(**config_args))\n",
    "        sdhf, sd = model_hf.state_dict(), model.state_dict()\n",
    "        sdhf_keys, sd_keys = sdhf.keys(), sd.keys() # .collect::<Vec<_>>() semantics\n",
    "        # filter\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # 2. copy\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        assert len(sdhf_keys) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sdhf_keys:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sdhf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sdhf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device)\n",
    "print(f'model loaded to {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 20 batches\n",
      "step: 0, loss: 10.90792179107666, latency(ms): 1442.24, throughput(tok/s): 11360.14\n",
      "step: 1, loss: 9.50654125213623, latency(ms): 1040.34, throughput(tok/s): 15748.66\n",
      "step: 2, loss: 9.271211624145508, latency(ms): 1039.74, throughput(tok/s): 15757.74\n",
      "step: 3, loss: 9.029306411743164, latency(ms): 1039.85, throughput(tok/s): 15756.09\n",
      "step: 4, loss: 8.81596851348877, latency(ms): 1039.94, throughput(tok/s): 15754.75\n",
      "step: 5, loss: 8.688678741455078, latency(ms): 1040.09, throughput(tok/s): 15752.48\n",
      "step: 6, loss: 8.45480728149414, latency(ms): 1040.02, throughput(tok/s): 15753.55\n",
      "step: 7, loss: 8.19499397277832, latency(ms): 1039.92, throughput(tok/s): 15755.11\n",
      "step: 8, loss: 7.922412395477295, latency(ms): 1039.92, throughput(tok/s): 15755.11\n",
      "step: 9, loss: 7.708868503570557, latency(ms): 1039.98, throughput(tok/s): 15754.22\n",
      "step: 10, loss: 7.543772220611572, latency(ms): 1039.99, throughput(tok/s): 15754.04\n",
      "step: 11, loss: 7.407567977905273, latency(ms): 1039.87, throughput(tok/s): 15755.75\n",
      "step: 12, loss: 7.214659690856934, latency(ms): 1039.89, throughput(tok/s): 15755.50\n",
      "step: 13, loss: 7.119818210601807, latency(ms): 1039.98, throughput(tok/s): 15754.12\n",
      "step: 14, loss: 7.064257621765137, latency(ms): 1039.93, throughput(tok/s): 15754.96\n",
      "step: 15, loss: 6.919295787811279, latency(ms): 1039.97, throughput(tok/s): 15754.33\n",
      "step: 16, loss: 6.888033866882324, latency(ms): 1040.08, throughput(tok/s): 15752.65\n",
      "step: 17, loss: 6.844876289367676, latency(ms): 1039.96, throughput(tok/s): 15754.48\n",
      "step: 18, loss: 6.822444915771484, latency(ms): 1039.91, throughput(tok/s): 15755.21\n",
      "step: 19, loss: 6.65519905090332, latency(ms): 1039.90, throughput(tok/s): 15755.40\n",
      "step: 20, loss: 6.559916019439697, latency(ms): 1039.81, throughput(tok/s): 15756.71\n",
      "step: 21, loss: 6.360528945922852, latency(ms): 1039.90, throughput(tok/s): 15755.44\n",
      "step: 22, loss: 6.419007301330566, latency(ms): 1039.86, throughput(tok/s): 15755.89\n",
      "step: 23, loss: 6.385975360870361, latency(ms): 1039.93, throughput(tok/s): 15754.88\n",
      "step: 24, loss: 6.33330774307251, latency(ms): 1039.96, throughput(tok/s): 15754.43\n",
      "step: 25, loss: 6.5498785972595215, latency(ms): 1040.08, throughput(tok/s): 15752.68\n",
      "step: 26, loss: 6.627231597900391, latency(ms): 1039.96, throughput(tok/s): 15754.51\n",
      "step: 27, loss: 6.519107818603516, latency(ms): 1040.06, throughput(tok/s): 15752.89\n",
      "step: 28, loss: 6.456545352935791, latency(ms): 1039.99, throughput(tok/s): 15753.97\n",
      "step: 29, loss: 6.345880031585693, latency(ms): 1039.84, throughput(tok/s): 15756.27\n",
      "step: 30, loss: 6.380766868591309, latency(ms): 1039.93, throughput(tok/s): 15754.87\n",
      "step: 31, loss: 6.417591094970703, latency(ms): 1039.78, throughput(tok/s): 15757.18\n",
      "step: 32, loss: 6.35863733291626, latency(ms): 1039.84, throughput(tok/s): 15756.30\n",
      "step: 33, loss: 6.395118713378906, latency(ms): 1039.79, throughput(tok/s): 15757.09\n",
      "step: 34, loss: 6.482184886932373, latency(ms): 1039.88, throughput(tok/s): 15755.73\n",
      "step: 35, loss: 6.344751358032227, latency(ms): 1039.87, throughput(tok/s): 15755.85\n",
      "step: 36, loss: 6.344614028930664, latency(ms): 1039.85, throughput(tok/s): 15756.05\n",
      "step: 37, loss: 6.351380825042725, latency(ms): 1039.94, throughput(tok/s): 15754.79\n",
      "step: 38, loss: 6.331134796142578, latency(ms): 1039.96, throughput(tok/s): 15754.49\n",
      "step: 39, loss: 6.1773200035095215, latency(ms): 1039.82, throughput(tok/s): 15756.61\n",
      "step: 40, loss: 6.326668739318848, latency(ms): 1039.86, throughput(tok/s): 15756.02\n",
      "step: 41, loss: 6.089095592498779, latency(ms): 1039.85, throughput(tok/s): 15756.14\n",
      "step: 42, loss: 6.227452754974365, latency(ms): 1039.88, throughput(tok/s): 15755.61\n",
      "step: 43, loss: 6.126423358917236, latency(ms): 1039.75, throughput(tok/s): 15757.59\n",
      "step: 44, loss: 6.0760297775268555, latency(ms): 1039.92, throughput(tok/s): 15755.03\n",
      "step: 45, loss: 6.285645961761475, latency(ms): 1039.81, throughput(tok/s): 15756.75\n",
      "step: 46, loss: 6.411369323730469, latency(ms): 1039.83, throughput(tok/s): 15756.49\n",
      "step: 47, loss: 6.290164947509766, latency(ms): 1039.76, throughput(tok/s): 15757.41\n",
      "step: 48, loss: 6.225734233856201, latency(ms): 1039.90, throughput(tok/s): 15755.36\n",
      "step: 49, loss: 6.137129306793213, latency(ms): 1039.81, throughput(tok/s): 15756.70\n",
      "6.137129306793213\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" training loop\n",
    "(Jordan et al. 2024) URL: https://github.com/KellerJordan/modded-nanogpt\n",
    "124M 10x speedup: 45m -> 4m\n",
    "========================================================================\n",
    "- network architecture: rotary embeddings, QK-norm, ReLU^2\n",
    "- muon optimizer\n",
    "- untie head & embedding, FP8 matmul for head, softcap logits (gemma 2)\n",
    "- projection and classification layers init to zero (muP)\n",
    "- skip connections from embedding to every block (and between) via U-net\n",
    "- flexattention with long-short sliding window attention (gemma 2), window size warmup\n",
    "\n",
    "        124M history:\n",
    "        01. 45.0m baseline\n",
    "        02. 31.4m tuned lr, rotary embeddings\n",
    "        03. 24.9m muon optimizer\n",
    "        04. 22.3m muon improvements\n",
    "        05. 15.2m pad embeddings, ReLU^2, zero init, QK-norm\n",
    "        06. 13.1m muon overhead\n",
    "        07. 12.0m pytorch 2.5.0\n",
    "        08. 10.8m united embedding and head\n",
    "        09. 08.2m value and embed skip connections, momentum warmup, logit softcap\n",
    "        10. 07.8m bfloat16 act\n",
    "        11. 07.2m u-net pattern skip connections, double lr\n",
    "        12. 05.0m 1024-ctx dense causal attn -> 64K-ctx flex attention\n",
    "        13. 04.6m attention window warmup\n",
    "        14. 04.4m value embededdings\n",
    "\"\"\"\n",
    "import time\n",
    "import torch\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. dataloader\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        with open('./data/shakespeare.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        encoder = tiktoken.get_encoding('gpt2')\n",
    "        self.tokens = torch.tensor(encoder.encode(text))\n",
    "        self.i = 0\n",
    "\n",
    "        print(f\"loaded {len(self.tokens)} tokens\")\n",
    "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        tokens = self.tokens[self.i:self.i+(B*T+1)]\n",
    "        X_BT, Y_BT = tokens[:-1].view(B,T), tokens[1:].view(B,T)\n",
    "        self.i += B*T\n",
    "        if self.i + (B*T+1) > len(self.tokens):\n",
    "            self.i = 0\n",
    "\n",
    "        return X_BT, Y_BT\n",
    "# print(X_BT)\n",
    "# print(Y_BT)\n",
    "# for b in range(B):\n",
    "#     print('batch', b)\n",
    "#     for t in range(T):\n",
    "#         context = X_BT[b, :t+1]\n",
    "#         target = Y_BT[b, t]\n",
    "#         print('x:', context, '->', 'y:', target)\n",
    "\n",
    "# print(\"==========================================\")\n",
    "\n",
    "# 2. training loop\n",
    "\n",
    "train_loader = DataLoaderLite(B=16, T=1024)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "steps, losses = [], []\n",
    "for step in range(50):\n",
    "    # preprocess\n",
    "    t0 = time.time()\n",
    "    X_BT, Y_BT = train_loader.next_batch()\n",
    "    X_BT, Y_BT = X_BT.to(device), Y_BT.to(device)\n",
    "\n",
    "    # 1. forward\n",
    "    optimizer.zero_grad()\n",
    "    logits_BTV, loss = model(X_BT, Y_BT)\n",
    "    # 2. backward\n",
    "    loss.backward()\n",
    "    # 3. step\n",
    "    optimizer.step()\n",
    "\n",
    "    # postprocess\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    latency = (t1-t0)*1000\n",
    "    throughput = (train_loader.B * train_loader.T) / (t1-t0)\n",
    "\n",
    "    steps.append(step)\n",
    "    losses.append(loss.log10().item())\n",
    "    print(f\"step: {step}, loss: {loss.item()}, latency(ms): {latency:.2f}, throughput(tok/s): {throughput:.2f}\")\n",
    "\n",
    "plt.plot(steps, losses)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model,?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " he but'd,\n",
      "\n",
      "\n",
      "'s of you thy of as he\n",
      "D\n",
      "> Hello, I'm a language model, not to,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      "\n",
      "\n",
      "That not are\n",
      "> Hello, I'm a language model, to: to with all be be, with:\n",
      "!\n",
      "KINGU not!\n",
      " the,\n",
      "\n",
      "\n",
      "> Hello, I'm a language model,; he a.\n",
      " and shall:\n",
      "\n",
      "And be,I your I and all,\n",
      "I his\n",
      "> Hello, I'm a language model, to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " him all,\n",
      "\n",
      "?\n",
      "\n",
      "IO of as, my\n"
     ]
    }
   ],
   "source": [
    "B, T_MAX = 5, 30\n",
    "model.eval()\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "tokens = encoder.encode(\"Hello, I'm a language model,\")\n",
    "tokens_T = torch.tensor(tokens, dtype=torch.long) # # (T,)\n",
    "tokens_BT = tokens_T.unsqueeze(0).repeat(5, 1) # (B,T)\n",
    "X_BT = tokens_BT.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "while X_BT.size(1) < T_MAX:\n",
    "    with torch.no_grad():\n",
    "        logits_BTV, _ = model(X_BT)\n",
    "        logits_BV = logits_BTV[:, -1, :]\n",
    "        probs_ = F.softmax(logits_BV, dim=-1)\n",
    "        topk_probs_, topk_indices_ = torch.topk(probs_, 50, dim=-1)\n",
    "\n",
    "        X_B1 = torch.gather(topk_indices_, -1, torch.multinomial(topk_probs_, 1))\n",
    "        X_BT = torch.cat((X_BT, X_B1), dim=1)\n",
    "\n",
    "for b in range(B):\n",
    "    tokens = X_BT[b, :T_MAX].tolist()\n",
    "    decoded = encoder.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
