{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "model loaded to cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model: gpt2\n",
    "- (Vaswani et al. 2017 https://arxiv.org/abs/1706.03762)\n",
    "- (Radford et al. 2019 https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- (Brown et al. 2020 https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "pre-gpt       ->    gpt2                                 URL\n",
    "-----------------------------------------------------------------------------------------\n",
    "- ReLU        ->    GeLU: (Hendrycks, Gimpel 2016)       https://arxiv.org/abs/1606.08415\n",
    "- BatchNorm   ->    LayerNorm: (Ba et al. 2016)          https://arxiv.org/abs/1607.06450\n",
    "- N/A         ->    Residuals: (He et al. 2015)          https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "\n",
    "Dimension key:\n",
    "\n",
    "# windows\n",
    "B: batch size\n",
    "T: sequence length\n",
    "\n",
    "# input/output\n",
    "V: vocabulary size\n",
    "D: model dimension (n_embd)\n",
    "\n",
    "# attention\n",
    "N: number of transformer blocks (n_layer)\n",
    "H: number of attention heads in a layer (n_head)\n",
    "K: size of each attention key or value (n_k)\n",
    "\"\"\"\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # windows: B, T\n",
    "    batch_size: int = -1   # B\n",
    "    block_size: int = 1024  # T\n",
    "    # input/output:  V, D\n",
    "    vocab_size: int = 50257  # V (256 bytes + 50,000 BPE merges + 1 <|endoftext|> token)\n",
    "    n_embd: int = 768      # D\n",
    "    # attn: NH\n",
    "    n_layer: int = 12      # N\n",
    "    n_head: int = 12       # H\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        T, D, H = config.block_size, config.n_embd, config.n_head\n",
    "        assert D % H == 0\n",
    "\n",
    "        self.H = H\n",
    "\n",
    "        self.c_attn = nn.Linear(D, 3 * D)\n",
    "        self.c_proj = nn.Linear(D, D)\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(T, T)).view(1, 1, T, T)) # tril -> bias for HF\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        B,T,D = X_BTD.shape\n",
    "        H = self.H\n",
    "        # 1. project to learned QKV subspaces Q=WqX, K=WkX, V=WvX\n",
    "        Wq_DK, Wk_DK, Wv_DK = self.c_attn(X_BTD).split(D, dim=2)\n",
    "        Q_BHTK, K_BHTK, V_BHTK = Wq_DK.view(B, T, H, D // H).transpose(1, 2), Wk_DK.view(B, T, H, D // H).transpose(1, 2), Wv_DK.view(B, T, H, D // H).transpose(1, 2)\n",
    "\n",
    "        # 2. evaluate scores A(QKV) = softmax(QK^T/sqrt(d_k))V\n",
    "        A_BHTT = Q_BHTK @ K_BHTK.transpose(-2, -1) * (1.0 / math.sqrt(K_BHTK.size(-1)))\n",
    "        A_BHTT = A_BHTT.masked_fill(self.bias[:, :, :T, :T]==0, float('-inf'))\n",
    "        A_BHTT = F.softmax(A_BHTT, dim=-1) # todo, when dim=-1?\n",
    "\n",
    "        # 3. contextualize the embeddings\n",
    "        S_BHTD = A_BHTT @ V_BHTK\n",
    "        S_BTD = S_BHTD.transpose(1, 2).contiguous().view(B, T, D) # performs cat\n",
    "        S_BTD = self.c_proj(S_BTD)\n",
    "\n",
    "        return S_BTD\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D = config.n_embd\n",
    "        self.c_fc = nn.Linear(D, 4*D) # projecting up to extract features from context embeddings\n",
    "        self.gelu = nn.GELU(approximate='tanh') # (Hendrycks et al. https://arxiv.org/abs/1606.08415)\n",
    "        self.c_proj = nn.Linear(4*D, D) # projecting back down to residual pathway\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        X_BT4D = self.c_fc(X_BTD)\n",
    "        X_BT4D = self.gelu(X_BT4D)\n",
    "        X_BTD = self.c_proj(X_BT4D)\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class LayerNorm(nn.Module): # manual inefficient LayerNorm implementation\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward():\n",
    "#         # ...\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D, H = config.n_embd, config.n_head\n",
    "        self.ln_1 = nn.LayerNorm(D)\n",
    "        self.attn = MHA(config)\n",
    "        self.mlp = FFN(config) # .mlp for HF\n",
    "        self.ln_2 = nn.LayerNorm(D)\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        # residuals:\n",
    "        # - (He et al. 2015 https://arxiv.org/abs/1512.03385)\n",
    "        # - (Elhage et al. 2021 https://transformer-circuits.pub/2021/framework/index.html)\n",
    "        X_BTD = X_BTD + self.attn(self.ln_1(X_BTD))\n",
    "        X_BTD = X_BTD + self.mlp(self.ln_2(X_BTD))\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        B, T = config.batch_size, config.block_size\n",
    "        V, D = config.vocab_size, config.n_embd\n",
    "        N, H = config.n_layer, config.n_head\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(V, D), # Wt\n",
    "            wpe = nn.Embedding(T, D), # Wp\n",
    "            h = nn.ModuleList([Block(config) for _ in range(N)]),\n",
    "            ln_f = nn.LayerNorm(D),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(D, V, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight # weight sharing (40m/120m ~30% save)\n",
    "        self.apply(self._init_weights) # weight init (roughly Xavier)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std=0.02 # default std for nn.Linear() and nn.Embedding(). nn.LayerNorm defaults are OK\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'GPT2_SCALE_INIT'):\n",
    "                std = (2 * self.config.n_layer ** -0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias) # instead of default of unit gaussian\n",
    "\n",
    "        if isinstance(module, nn.Linear) or isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std) # ~ 1/sqrt(D={768, 1024, 1280, 1600}) (Xavier init)\n",
    "\n",
    "    def forward(self, X_BT, Y_BT=None): # Some(Y_BT) => training, None => inference\n",
    "        B, T = X_BT.shape\n",
    "        # 1. embedding: BTD\n",
    "        Xtok_BTD = self.transformer.wte(X_BT)\n",
    "        Xpos_TD = self.transformer.wpe(torch.arange(0, T, dtype=torch.long, device=X_BT.device))\n",
    "        X_BTD = Xtok_BTD + Xpos_TD\n",
    "        # 2. N transformer blocks: Nx(BTD -> BTK -> BTD)\n",
    "        for h in self.transformer.h:\n",
    "            X_BTD = h(X_BTD)\n",
    "        # 3. logits: BTD -> BTV\n",
    "        X_BTD = self.transformer.ln_f(X_BTD)\n",
    "        logits_BTV = self.lm_head(X_BTD)\n",
    "        loss = None\n",
    "\n",
    "        if Y_BT is not None:\n",
    "            V = self.config.vocab_size\n",
    "            loss = F.cross_entropy(logits_BTV.view(B*T, V), Y_BT.view(B*T)) # reshape for .cross_entropy()\n",
    "        return logits_BTV, loss\n",
    " \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "\n",
    "\n",
    "\n",
    "        # 1. model init\n",
    "        model_hf, model = GPT2LMHeadModel.from_pretrained(model_type), GPT(GPTConfig(**config_args))\n",
    "        sdhf, sd = model_hf.state_dict(), model.state_dict()\n",
    "        sdhf_keys, sd_keys = sdhf.keys(), sd.keys() # .collect::<Vec<_>>() semantics\n",
    "        # filter\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # 2. copy\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        assert len(sdhf_keys) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sdhf_keys:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sdhf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sdhf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device)\n",
    "print(f'model loaded to {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 20 batches\n",
      "step: 0, loss: 10.90761947631836, latency(ms): 940.86, throughput(tok/s): 17413.90\n",
      "step: 1, loss: 9.506199836730957, latency(ms): 336.34, throughput(tok/s): 48712.27\n",
      "step: 2, loss: 9.27074909210205, latency(ms): 335.65, throughput(tok/s): 48812.72\n",
      "step: 3, loss: 9.029440879821777, latency(ms): 335.74, throughput(tok/s): 48799.83\n",
      "step: 4, loss: 8.815587043762207, latency(ms): 335.76, throughput(tok/s): 48796.99\n",
      "step: 5, loss: 8.685736656188965, latency(ms): 335.66, throughput(tok/s): 48811.02\n",
      "step: 6, loss: 8.453493118286133, latency(ms): 335.68, throughput(tok/s): 48808.42\n",
      "step: 7, loss: 8.196279525756836, latency(ms): 335.75, throughput(tok/s): 48798.30\n",
      "step: 8, loss: 7.922240257263184, latency(ms): 335.73, throughput(tok/s): 48800.97\n",
      "step: 9, loss: 7.709371089935303, latency(ms): 335.91, throughput(tok/s): 48774.65\n",
      "step: 10, loss: 7.542871475219727, latency(ms): 335.77, throughput(tok/s): 48796.02\n",
      "step: 11, loss: 7.40784215927124, latency(ms): 335.77, throughput(tok/s): 48795.88\n",
      "step: 12, loss: 7.213770866394043, latency(ms): 335.81, throughput(tok/s): 48790.09\n",
      "step: 13, loss: 7.11962890625, latency(ms): 335.77, throughput(tok/s): 48795.50\n",
      "step: 14, loss: 7.0632829666137695, latency(ms): 335.63, throughput(tok/s): 48815.46\n",
      "step: 15, loss: 6.917172431945801, latency(ms): 335.82, throughput(tok/s): 48787.63\n",
      "step: 16, loss: 6.888372421264648, latency(ms): 335.76, throughput(tok/s): 48796.43\n",
      "step: 17, loss: 6.845456123352051, latency(ms): 335.72, throughput(tok/s): 48802.63\n",
      "step: 18, loss: 6.824825286865234, latency(ms): 335.71, throughput(tok/s): 48803.36\n",
      "step: 19, loss: 6.656229019165039, latency(ms): 335.80, throughput(tok/s): 48791.34\n",
      "step: 20, loss: 6.5603790283203125, latency(ms): 335.77, throughput(tok/s): 48794.98\n",
      "step: 21, loss: 6.359302520751953, latency(ms): 335.76, throughput(tok/s): 48796.47\n",
      "step: 22, loss: 6.419401168823242, latency(ms): 335.75, throughput(tok/s): 48797.78\n",
      "step: 23, loss: 6.385687828063965, latency(ms): 335.71, throughput(tok/s): 48803.74\n",
      "step: 24, loss: 6.334146976470947, latency(ms): 335.66, throughput(tok/s): 48810.71\n",
      "step: 25, loss: 6.55081844329834, latency(ms): 335.76, throughput(tok/s): 48796.99\n",
      "step: 26, loss: 6.627254486083984, latency(ms): 335.65, throughput(tok/s): 48812.06\n",
      "step: 27, loss: 6.51859712600708, latency(ms): 335.98, throughput(tok/s): 48765.30\n",
      "step: 28, loss: 6.455625057220459, latency(ms): 335.68, throughput(tok/s): 48807.87\n",
      "step: 29, loss: 6.346333026885986, latency(ms): 335.68, throughput(tok/s): 48807.97\n",
      "step: 30, loss: 6.380963325500488, latency(ms): 335.67, throughput(tok/s): 48809.29\n",
      "step: 31, loss: 6.415824890136719, latency(ms): 335.70, throughput(tok/s): 48805.44\n",
      "step: 32, loss: 6.360761642456055, latency(ms): 335.61, throughput(tok/s): 48818.76\n",
      "step: 33, loss: 6.396295070648193, latency(ms): 335.64, throughput(tok/s): 48814.59\n",
      "step: 34, loss: 6.481586456298828, latency(ms): 335.65, throughput(tok/s): 48813.41\n",
      "step: 35, loss: 6.343954086303711, latency(ms): 335.64, throughput(tok/s): 48813.69\n",
      "step: 36, loss: 6.3452887535095215, latency(ms): 335.58, throughput(tok/s): 48822.88\n",
      "step: 37, loss: 6.351369380950928, latency(ms): 335.67, throughput(tok/s): 48810.47\n",
      "step: 38, loss: 6.3308305740356445, latency(ms): 335.72, throughput(tok/s): 48802.39\n",
      "step: 39, loss: 6.1768083572387695, latency(ms): 335.61, throughput(tok/s): 48819.14\n",
      "step: 40, loss: 6.325316429138184, latency(ms): 335.73, throughput(tok/s): 48800.73\n",
      "step: 41, loss: 6.0873188972473145, latency(ms): 335.59, throughput(tok/s): 48821.04\n",
      "step: 42, loss: 6.227026462554932, latency(ms): 335.58, throughput(tok/s): 48823.30\n",
      "step: 43, loss: 6.126590728759766, latency(ms): 335.66, throughput(tok/s): 48811.54\n",
      "step: 44, loss: 6.075991630554199, latency(ms): 335.65, throughput(tok/s): 48813.35\n",
      "step: 45, loss: 6.284213542938232, latency(ms): 335.56, throughput(tok/s): 48825.35\n",
      "step: 46, loss: 6.411177635192871, latency(ms): 335.64, throughput(tok/s): 48814.70\n",
      "step: 47, loss: 6.291101455688477, latency(ms): 335.73, throughput(tok/s): 48800.90\n",
      "step: 48, loss: 6.223714828491211, latency(ms): 335.56, throughput(tok/s): 48826.21\n",
      "step: 49, loss: 6.135469913482666, latency(ms): 335.65, throughput(tok/s): 48812.86\n",
      "6.135469913482666\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" training loop\n",
    "(Jordan et al. 2024) URL: https://github.com/KellerJordan/modded-nanogpt\n",
    "124M 10x speedup: 45m -> 4m\n",
    "========================================================================\n",
    "- network architecture: rotary embeddings, QK-norm, ReLU^2\n",
    "- muon optimizer\n",
    "- untie head & embedding, FP8 matmul for head, softcap logits (gemma 2)\n",
    "- projection and classification layers init to zero (muP)\n",
    "- skip connections from embedding to every block (and between) via U-net\n",
    "- flexattention with long-short sliding window attention (gemma 2), window size warmup\n",
    "\n",
    "        124M history:\n",
    "        01. 45.0m baseline\n",
    "        02. 31.4m tuned lr, rotary embeddings\n",
    "        03. 24.9m muon optimizer\n",
    "        04. 22.3m muon improvements\n",
    "        05. 15.2m pad embeddings, ReLU^2, zero init, QK-norm\n",
    "        06. 13.1m muon overhead\n",
    "        07. 12.0m pytorch 2.5.0\n",
    "        08. 10.8m united embedding and head\n",
    "        09. 08.2m value and embed skip connections, momentum warmup, logit softcap\n",
    "        10. 07.8m bfloat16 act\n",
    "        11. 07.2m u-net pattern skip connections, double lr\n",
    "        12. 05.0m 1024-ctx dense causal attn -> 64K-ctx flex attention\n",
    "        13. 04.6m attention window warmup\n",
    "        14. 04.4m value embededdings\n",
    "\"\"\"\n",
    "import time\n",
    "import torch\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. dataloader\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        with open('./data/shakespeare.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        encoder = tiktoken.get_encoding('gpt2')\n",
    "        self.tokens = torch.tensor(encoder.encode(text))\n",
    "        self.i = 0\n",
    "\n",
    "        print(f\"loaded {len(self.tokens)} tokens\")\n",
    "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        tokens = self.tokens[self.i:self.i+(B*T+1)]\n",
    "        X_BT, Y_BT = tokens[:-1].view(B,T), tokens[1:].view(B,T)\n",
    "        self.i += B*T\n",
    "        if self.i + (B*T+1) > len(self.tokens):\n",
    "            self.i = 0\n",
    "\n",
    "        return X_BT, Y_BT\n",
    "# print(X_BT)\n",
    "# print(Y_BT)\n",
    "# for b in range(B):\n",
    "#     print('batch', b)\n",
    "#     for t in range(T):\n",
    "#         context = X_BT[b, :t+1]\n",
    "#         target = Y_BT[b, t]\n",
    "#         print('x:', context, '->', 'y:', target)\n",
    "\n",
    "# print(\"==========================================\")\n",
    "\n",
    "# 2. training loop\n",
    "\n",
    "train_loader = DataLoaderLite(B=16, T=1024)\n",
    "torch.set_float32_matmul_precision('high') # highest (fp32) -> high (tf32). 3x instead of advertised 8x speedup (deep learning is memory-bound)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "steps, losses = [], []\n",
    "for step in range(50):\n",
    "    # preprocess\n",
    "    t0 = time.time()\n",
    "    X_BT, Y_BT = train_loader.next_batch()\n",
    "    X_BT, Y_BT = X_BT.to(device), Y_BT.to(device)\n",
    "\n",
    "    # 1. forward\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16): # ampere and up\n",
    "        logits_BTV, loss = model(X_BT, Y_BT)\n",
    "    # 2. backward\n",
    "    loss.backward()\n",
    "    # 3. step\n",
    "    optimizer.step()\n",
    "\n",
    "    # postprocess\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    latency = (t1-t0)*1000\n",
    "    throughput = (train_loader.B * train_loader.T) / (t1-t0)\n",
    "\n",
    "    steps.append(step)\n",
    "    losses.append(loss.log10().item())\n",
    "    print(f\"step: {step}, loss: {loss.item()}, latency(ms): {latency:.2f}, throughput(tok/s): {throughput:.2f}\")\n",
    "\n",
    "plt.plot(steps, losses)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model,?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " he but'd,\n",
      "\n",
      "\n",
      "'s of you thy of as he\n",
      "D\n",
      "> Hello, I'm a language model,!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ofI of a?\n",
      "\n",
      ":\n",
      "\n",
      "\n",
      "That not shall\n",
      "> Hello, I'm a language model, to: to with all be be, with:\n",
      " of his no' not!\n",
      " you,\n",
      "\n",
      "\n",
      "> Hello, I'm a language model,; he a.\n",
      " and shall:\n",
      "\n",
      "And be,I it my and all,\n",
      "I his\n",
      "> Hello, I'm a language model, to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "As all,\n",
      "\n",
      "?\n",
      "\n",
      " it to as, my\n"
     ]
    }
   ],
   "source": [
    "B, T_MAX = 5, 30\n",
    "model.eval()\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "tokens = encoder.encode(\"Hello, I'm a language model,\")\n",
    "tokens_T = torch.tensor(tokens, dtype=torch.long) # # (T,)\n",
    "tokens_BT = tokens_T.unsqueeze(0).repeat(5, 1) # (B,T)\n",
    "X_BT = tokens_BT.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "while X_BT.size(1) < T_MAX:\n",
    "    with torch.no_grad():\n",
    "        logits_BTV, _ = model(X_BT)\n",
    "        logits_BV = logits_BTV[:, -1, :]\n",
    "        probs_ = F.softmax(logits_BV, dim=-1)\n",
    "        topk_probs_, topk_indices_ = torch.topk(probs_, 50, dim=-1)\n",
    "\n",
    "        X_B1 = torch.gather(topk_indices_, -1, torch.multinomial(topk_probs_, 1))\n",
    "        X_BT = torch.cat((X_BT, X_B1), dim=1)\n",
    "\n",
    "for b in range(B):\n",
    "    tokens = X_BT[b, :T_MAX].tolist()\n",
    "    decoded = encoder.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
