{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "model loaded to cuda\n",
      "model compiled to cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model: gpt2\n",
    "- (Vaswani et al. 2017 https://arxiv.org/abs/1706.03762)\n",
    "- (Radford et al. 2019 https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- (Brown et al. 2020 https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "pre-gpt       ->    gpt2                                 URL\n",
    "-----------------------------------------------------------------------------------------\n",
    "- ReLU        ->    GeLU: (Hendrycks, Gimpel 2016)       https://arxiv.org/abs/1606.08415\n",
    "- BatchNorm   ->    LayerNorm: (Ba et al. 2016)          https://arxiv.org/abs/1607.06450\n",
    "- N/A         ->    Residuals: (He et al. 2015)          https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "\n",
    "Dimension key:\n",
    "\n",
    "# windows\n",
    "B: batch size\n",
    "T: sequence length\n",
    "\n",
    "# input/output\n",
    "V: vocabulary size\n",
    "D: model dimension (n_embd)\n",
    "\n",
    "# attention\n",
    "N: number of transformer blocks (n_layer)\n",
    "H: number of attention heads in a layer (n_head)\n",
    "K: size of each attention key or value (n_k)\n",
    "\"\"\"\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device {device}\")\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # windows: B, T\n",
    "    batch_size: int = -1   # B\n",
    "    block_size: int = 1024  # T\n",
    "    # input/output:  V, D\n",
    "    vocab_size: int = 50257  # V (256 bytes + 50,000 BPE merges + 1 <|endoftext|> token)\n",
    "    n_embd: int = 768      # D\n",
    "    # attn: NH\n",
    "    n_layer: int = 12      # N\n",
    "    n_head: int = 12       # H\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        T, D, H = config.block_size, config.n_embd, config.n_head\n",
    "        assert D % H == 0\n",
    "\n",
    "        self.H = H\n",
    "\n",
    "        self.c_attn = nn.Linear(D, 3 * D)\n",
    "        self.c_proj = nn.Linear(D, D)\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(T, T)).view(1, 1, T, T)) # tril -> bias for HF\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        B,T,D = X_BTD.shape\n",
    "        H = self.H\n",
    "        # 1. project to learned QKV subspaces Q=WqX, K=WkX, V=WvX\n",
    "        Wq_DK, Wk_DK, Wv_DK = self.c_attn(X_BTD).split(D, dim=2)\n",
    "        Q_BHTK, K_BHTK, V_BHTK = Wq_DK.view(B, T, H, D // H).transpose(1, 2), Wk_DK.view(B, T, H, D // H).transpose(1, 2), Wv_DK.view(B, T, H, D // H).transpose(1, 2)\n",
    "\n",
    "        # 2. evaluate scores A(QKV) = softmax(QK^T/sqrt(d_k))V\n",
    "        A_BHTT = Q_BHTK @ K_BHTK.transpose(-2, -1) * (1.0 / math.sqrt(K_BHTK.size(-1)))\n",
    "        A_BHTT = A_BHTT.masked_fill(self.bias[:, :, :T, :T]==0, float('-inf'))\n",
    "        A_BHTT = F.softmax(A_BHTT, dim=-1) # todo, when dim=-1?\n",
    "\n",
    "        # 3. contextualize the embeddings\n",
    "        S_BHTD = A_BHTT @ V_BHTK\n",
    "        S_BTD = S_BHTD.transpose(1, 2).contiguous().view(B, T, D) # performs cat\n",
    "        S_BTD = self.c_proj(S_BTD)\n",
    "\n",
    "        return S_BTD\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D = config.n_embd\n",
    "        self.c_fc = nn.Linear(D, 4*D) # projecting up to extract features from context embeddings\n",
    "        self.gelu = nn.GELU(approximate='tanh') # (Hendrycks et al. https://arxiv.org/abs/1606.08415)\n",
    "        self.c_proj = nn.Linear(4*D, D) # projecting back down to residual pathway\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        X_BT4D = self.c_fc(X_BTD)\n",
    "        X_BT4D = self.gelu(X_BT4D)\n",
    "        X_BTD = self.c_proj(X_BT4D)\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class LayerNorm(nn.Module): # manual inefficient LayerNorm implementation\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward():\n",
    "#         # ...\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D, H = config.n_embd, config.n_head\n",
    "        self.ln_1 = nn.LayerNorm(D)\n",
    "        self.attn = MHA(config)\n",
    "        self.mlp = FFN(config) # .mlp for HF\n",
    "        self.ln_2 = nn.LayerNorm(D)\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        # residuals:\n",
    "        # - (He et al. 2015 https://arxiv.org/abs/1512.03385)\n",
    "        # - (Elhage et al. 2021 https://transformer-circuits.pub/2021/framework/index.html)\n",
    "        X_BTD = X_BTD + self.attn(self.ln_1(X_BTD))\n",
    "        X_BTD = X_BTD + self.mlp(self.ln_2(X_BTD))\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        B, T = config.batch_size, config.block_size\n",
    "        V, D = config.vocab_size, config.n_embd\n",
    "        N, H = config.n_layer, config.n_head\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(V, D), # Wt\n",
    "            wpe = nn.Embedding(T, D), # Wp\n",
    "            h = nn.ModuleList([Block(config) for _ in range(N)]),\n",
    "            ln_f = nn.LayerNorm(D),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(D, V, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight # weight sharing (40m/120m ~30% save)\n",
    "        self.apply(self._init_weights) # weight init (roughly Xavier)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std=0.02 # default std for nn.Linear() and nn.Embedding(). nn.LayerNorm defaults are OK\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'GPT2_SCALE_INIT'):\n",
    "                std = (2 * self.config.n_layer ** -0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias) # instead of default of unit gaussian\n",
    "\n",
    "        if isinstance(module, nn.Linear) or isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std) # ~ 1/sqrt(D={768, 1024, 1280, 1600}) (Xavier init)\n",
    "\n",
    "    def forward(self, X_BT, Y_BT=None): # Some(Y_BT) => training, None => inference\n",
    "        B, T = X_BT.shape\n",
    "        # 1. embedding: BTD\n",
    "        Xtok_BTD = self.transformer.wte(X_BT)\n",
    "        Xpos_TD = self.transformer.wpe(torch.arange(0, T, dtype=torch.long, device=X_BT.device))\n",
    "        X_BTD = Xtok_BTD + Xpos_TD\n",
    "        # 2. N transformer blocks: Nx(BTD -> BTK -> BTD)\n",
    "        for h in self.transformer.h:\n",
    "            X_BTD = h(X_BTD)\n",
    "        # 3. logits: BTD -> BTV\n",
    "        X_BTD = self.transformer.ln_f(X_BTD)\n",
    "        logits_BTV = self.lm_head(X_BTD)\n",
    "        loss = None\n",
    "\n",
    "        if Y_BT is not None:\n",
    "            V = self.config.vocab_size\n",
    "            loss = F.cross_entropy(logits_BTV.view(B*T, V), Y_BT.view(B*T)) # reshape for .cross_entropy()\n",
    "        return logits_BTV, loss\n",
    " \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "\n",
    "\n",
    "\n",
    "        # 1. model init\n",
    "        model_hf, model = GPT2LMHeadModel.from_pretrained(model_type), GPT(GPTConfig(**config_args))\n",
    "        sdhf, sd = model_hf.state_dict(), model.state_dict()\n",
    "        sdhf_keys, sd_keys = sdhf.keys(), sd.keys() # .collect::<Vec<_>>() semantics\n",
    "        # filter\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # 2. copy\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        assert len(sdhf_keys) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sdhf_keys:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sdhf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sdhf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device)\n",
    "print(f'model loaded to {device}')\n",
    "model = torch.compile(model)\n",
    "print(f'model compiled to {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 20 batches\n",
      "step: 0, loss: 10.907681465148926, latency(ms): 42377.21, throughput(tok/s): 386.62\n",
      "step: 1, loss: 9.505548477172852, latency(ms): 139.11, throughput(tok/s): 117776.62\n",
      "step: 2, loss: 9.270233154296875, latency(ms): 138.16, throughput(tok/s): 118591.04\n",
      "step: 3, loss: 9.030075073242188, latency(ms): 138.28, throughput(tok/s): 118484.92\n",
      "step: 4, loss: 8.81601619720459, latency(ms): 137.87, throughput(tok/s): 118833.44\n",
      "step: 5, loss: 8.688018798828125, latency(ms): 138.08, throughput(tok/s): 118659.44\n",
      "step: 6, loss: 8.454099655151367, latency(ms): 137.85, throughput(tok/s): 118855.23\n",
      "step: 7, loss: 8.194442749023438, latency(ms): 138.07, throughput(tok/s): 118662.51\n",
      "step: 8, loss: 7.922466278076172, latency(ms): 137.83, throughput(tok/s): 118868.38\n",
      "step: 9, loss: 7.709846496582031, latency(ms): 138.13, throughput(tok/s): 118615.61\n",
      "step: 10, loss: 7.542548179626465, latency(ms): 137.85, throughput(tok/s): 118850.70\n",
      "step: 11, loss: 7.406991004943848, latency(ms): 138.15, throughput(tok/s): 118598.61\n",
      "step: 12, loss: 7.213421821594238, latency(ms): 137.87, throughput(tok/s): 118836.32\n",
      "step: 13, loss: 7.11948299407959, latency(ms): 138.08, throughput(tok/s): 118655.13\n",
      "step: 14, loss: 7.064175605773926, latency(ms): 137.80, throughput(tok/s): 118900.67\n",
      "step: 15, loss: 6.9192280769348145, latency(ms): 138.03, throughput(tok/s): 118697.97\n",
      "step: 16, loss: 6.8880615234375, latency(ms): 137.88, throughput(tok/s): 118829.12\n",
      "step: 17, loss: 6.844491958618164, latency(ms): 138.14, throughput(tok/s): 118603.53\n",
      "step: 18, loss: 6.822299480438232, latency(ms): 137.79, throughput(tok/s): 118901.29\n",
      "step: 19, loss: 6.654667377471924, latency(ms): 138.10, throughput(tok/s): 118634.44\n",
      "step: 20, loss: 6.559174537658691, latency(ms): 137.80, throughput(tok/s): 118895.53\n",
      "step: 21, loss: 6.359758377075195, latency(ms): 138.12, throughput(tok/s): 118623.39\n",
      "step: 22, loss: 6.418750286102295, latency(ms): 137.81, throughput(tok/s): 118884.22\n",
      "step: 23, loss: 6.385972499847412, latency(ms): 138.09, throughput(tok/s): 118647.96\n",
      "step: 24, loss: 6.333276748657227, latency(ms): 138.09, throughput(tok/s): 118644.48\n",
      "step: 25, loss: 6.549709320068359, latency(ms): 138.12, throughput(tok/s): 118624.21\n",
      "step: 26, loss: 6.627361297607422, latency(ms): 137.83, throughput(tok/s): 118871.26\n",
      "step: 27, loss: 6.518463611602783, latency(ms): 138.08, throughput(tok/s): 118656.77\n",
      "step: 28, loss: 6.456533908843994, latency(ms): 137.79, throughput(tok/s): 118908.70\n",
      "step: 29, loss: 6.344961166381836, latency(ms): 138.05, throughput(tok/s): 118678.49\n",
      "step: 30, loss: 6.380151271820068, latency(ms): 137.85, throughput(tok/s): 118856.46\n",
      "step: 31, loss: 6.417163848876953, latency(ms): 138.04, throughput(tok/s): 118690.59\n",
      "step: 32, loss: 6.357883453369141, latency(ms): 137.86, throughput(tok/s): 118842.07\n",
      "step: 33, loss: 6.394505023956299, latency(ms): 138.14, throughput(tok/s): 118602.30\n",
      "step: 34, loss: 6.481366157531738, latency(ms): 137.83, throughput(tok/s): 118870.44\n",
      "step: 35, loss: 6.3440117835998535, latency(ms): 138.14, throughput(tok/s): 118602.09\n",
      "step: 36, loss: 6.343644142150879, latency(ms): 137.81, throughput(tok/s): 118891.62\n",
      "step: 37, loss: 6.350149154663086, latency(ms): 138.08, throughput(tok/s): 118655.34\n",
      "step: 38, loss: 6.329835891723633, latency(ms): 137.88, throughput(tok/s): 118831.18\n",
      "step: 39, loss: 6.175869464874268, latency(ms): 138.41, throughput(tok/s): 118375.93\n",
      "step: 40, loss: 6.326120376586914, latency(ms): 137.81, throughput(tok/s): 118890.39\n",
      "step: 41, loss: 6.088887691497803, latency(ms): 138.09, throughput(tok/s): 118645.30\n",
      "step: 42, loss: 6.2277021408081055, latency(ms): 137.80, throughput(tok/s): 118898.82\n",
      "step: 43, loss: 6.126008033752441, latency(ms): 138.11, throughput(tok/s): 118631.58\n",
      "step: 44, loss: 6.075800895690918, latency(ms): 137.90, throughput(tok/s): 118814.74\n",
      "step: 45, loss: 6.285060405731201, latency(ms): 138.14, throughput(tok/s): 118606.60\n",
      "step: 46, loss: 6.410991668701172, latency(ms): 138.20, throughput(tok/s): 118552.78\n",
      "step: 47, loss: 6.289773941040039, latency(ms): 138.43, throughput(tok/s): 118352.48\n",
      "step: 48, loss: 6.224841117858887, latency(ms): 137.97, throughput(tok/s): 118746.17\n",
      "step: 49, loss: 6.136336326599121, latency(ms): 138.03, throughput(tok/s): 118697.97\n",
      "6.136336326599121\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" training loop\n",
    "(Jordan et al. 2024) URL: https://github.com/KellerJordan/modded-nanogpt\n",
    "124M 10x speedup: 45m -> 4m\n",
    "========================================================================\n",
    "- network architecture: rotary embeddings, QK-norm, ReLU^2\n",
    "- muon optimizer\n",
    "- untie head & embedding, FP8 matmul for head, softcap logits (gemma 2)\n",
    "- projection and classification layers init to zero (muP)\n",
    "- skip connections from embedding to every block (and between) via U-net\n",
    "- flexattention with long-short sliding window attention (gemma 2), window size warmup\n",
    "\n",
    "        124M history:\n",
    "        01. 45.0m baseline\n",
    "        02. 31.4m tuned lr, rotary embeddings\n",
    "        03. 24.9m muon optimizer\n",
    "        04. 22.3m muon improvements\n",
    "        05. 15.2m pad embeddings, ReLU^2, zero init, QK-norm\n",
    "        06. 13.1m muon overhead\n",
    "        07. 12.0m pytorch 2.5.0\n",
    "        08. 10.8m united embedding and head\n",
    "        09. 08.2m value and embed skip connections, momentum warmup, logit softcap\n",
    "        10. 07.8m bfloat16 act\n",
    "        11. 07.2m u-net pattern skip connections, double lr\n",
    "        12. 05.0m 1024-ctx dense causal attn -> 64K-ctx flex attention\n",
    "        13. 04.6m attention window warmup\n",
    "        14. 04.4m value embededdings\n",
    "\"\"\"\n",
    "import time\n",
    "import torch\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. dataloader\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        with open('./data/shakespeare.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        encoder = tiktoken.get_encoding('gpt2')\n",
    "        self.tokens = torch.tensor(encoder.encode(text))\n",
    "        self.i = 0\n",
    "\n",
    "        print(f\"loaded {len(self.tokens)} tokens\")\n",
    "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        tokens = self.tokens[self.i:self.i+(B*T+1)]\n",
    "        X_BT, Y_BT = tokens[:-1].view(B,T), tokens[1:].view(B,T)\n",
    "        self.i += B*T\n",
    "        if self.i + (B*T+1) > len(self.tokens):\n",
    "            self.i = 0\n",
    "\n",
    "        return X_BT, Y_BT\n",
    "# print(X_BT)\n",
    "# print(Y_BT)\n",
    "# for b in range(B):\n",
    "#     print('batch', b)\n",
    "#     for t in range(T):\n",
    "#         context = X_BT[b, :t+1]\n",
    "#         target = Y_BT[b, t]\n",
    "#         print('x:', context, '->', 'y:', target)\n",
    "\n",
    "# print(\"==========================================\")\n",
    "\n",
    "# 2. training loop\n",
    "\n",
    "train_loader = DataLoaderLite(B=16, T=1024)\n",
    "torch.set_float32_matmul_precision('high') # highest (fp32) -> high (tf32). 3x instead of advertised 8x speedup (deep learning is memory-bound)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "steps, losses = [], []\n",
    "for step in range(50):\n",
    "    # preprocess\n",
    "    t0 = time.time()\n",
    "    X_BT, Y_BT = train_loader.next_batch()\n",
    "    X_BT, Y_BT = X_BT.to(device), Y_BT.to(device)\n",
    "\n",
    "    # 1. forward\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16): # ampere and up\n",
    "        logits_BTV, loss = model(X_BT, Y_BT)\n",
    "    # 2. backward\n",
    "    loss.backward()\n",
    "    # 3. step\n",
    "    optimizer.step()\n",
    "\n",
    "    # postprocess\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    latency = (t1-t0)*1000\n",
    "    throughput = (train_loader.B * train_loader.T) / (t1-t0)\n",
    "\n",
    "    steps.append(step)\n",
    "    losses.append(loss.log10().item())\n",
    "    print(f\"step: {step}, loss: {loss.item()}, latency(ms): {latency:.2f}, throughput(tok/s): {throughput:.2f}\")\n",
    "\n",
    "plt.plot(steps, losses)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model,?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " he but'd,\n",
      "\n",
      "\n",
      "'s of you thy of as this\n",
      " in\n",
      "> Hello, I'm a language model, not to,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " beI of a?\n",
      "\n",
      "The for me this not's shall\n",
      "> Hello, I'm a language model, to: to with all be be, with:\n",
      "DIO noEN not!\n",
      " you,\n",
      "\n",
      "\n",
      "> Hello, I'm a language model, of your a.\n",
      " and shall:\n",
      "\n",
      "And be,I it my and all,\n",
      "I his\n",
      "> Hello, I'm a language model, to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'s all,\n",
      "\n",
      "?\n",
      "\n",
      "A to as, my\n"
     ]
    }
   ],
   "source": [
    "B, T_MAX = 5, 30\n",
    "model.eval()\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "tokens = encoder.encode(\"Hello, I'm a language model,\")\n",
    "tokens_T = torch.tensor(tokens, dtype=torch.long) # # (T,)\n",
    "tokens_BT = tokens_T.unsqueeze(0).repeat(5, 1) # (B,T)\n",
    "X_BT = tokens_BT.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "while X_BT.size(1) < T_MAX:\n",
    "    with torch.no_grad():\n",
    "        logits_BTV, _ = model(X_BT)\n",
    "        logits_BV = logits_BTV[:, -1, :]\n",
    "        probs_ = F.softmax(logits_BV, dim=-1)\n",
    "        topk_probs_, topk_indices_ = torch.topk(probs_, 50, dim=-1)\n",
    "\n",
    "        X_B1 = torch.gather(topk_indices_, -1, torch.multinomial(topk_probs_, 1))\n",
    "        X_BT = torch.cat((X_BT, X_B1), dim=1)\n",
    "\n",
    "for b in range(B):\n",
    "    tokens = X_BT[b, :T_MAX].tolist()\n",
    "    decoded = encoder.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
