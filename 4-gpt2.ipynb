{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "model loaded to cuda\n",
      "model compiled to cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model: gpt2\n",
    "- (Vaswani et al. 2017 https://arxiv.org/abs/1706.03762)\n",
    "- (Radford et al. 2019 https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- (Brown et al. 2020 https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "pre-gpt       ->    gpt2                                 URL\n",
    "-----------------------------------------------------------------------------------------\n",
    "- ReLU        ->    GeLU: (Hendrycks, Gimpel 2016)       https://arxiv.org/abs/1606.08415\n",
    "- BatchNorm   ->    LayerNorm: (Ba et al. 2016)          https://arxiv.org/abs/1607.06450\n",
    "- N/A         ->    Residuals: (He et al. 2015)          https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "\n",
    "Dimension key:\n",
    "\n",
    "# windows\n",
    "B: batch size\n",
    "T: sequence length\n",
    "\n",
    "# input/output\n",
    "V: vocabulary size\n",
    "D: model dimension (n_embd)\n",
    "\n",
    "# attention\n",
    "N: number of transformer blocks (n_layer)\n",
    "H: number of attention heads in a layer (n_head)\n",
    "K: size of each attention key or value (n_k)\n",
    "\"\"\"\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device {device}\")\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # windows: B, T\n",
    "    batch_size: int = -1   # B\n",
    "    block_size: int = 1024  # T\n",
    "    # input/output:  V, D\n",
    "    vocab_size: int = 50304  # V (256 bytes + 50,000 BPE merges + 1 <|endoftext|> token)\n",
    "    n_embd: int = 768      # D\n",
    "    # attn: NH\n",
    "    n_layer: int = 12      # N\n",
    "    n_head: int = 12       # H\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        T, D, H = config.block_size, config.n_embd, config.n_head\n",
    "        assert D % H == 0\n",
    "\n",
    "        self.H = H\n",
    "\n",
    "        self.c_attn = nn.Linear(D, 3 * D)\n",
    "        self.c_proj = nn.Linear(D, D)\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(T, T)).view(1, 1, T, T)) # tril -> bias for HF\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        B,T,D = X_BTD.shape\n",
    "        H = self.H\n",
    "        # 1. project to learned QKV subspaces Q=WqX, K=WkX, V=WvX\n",
    "        Wq_DK, Wk_DK, Wv_DK = self.c_attn(X_BTD).split(D, dim=2)\n",
    "        Q_BHTK, K_BHTK, V_BHTK = Wq_DK.view(B, T, H, D // H).transpose(1, 2), Wk_DK.view(B, T, H, D // H).transpose(1, 2), Wv_DK.view(B, T, H, D // H).transpose(1, 2)\n",
    "\n",
    "        # 2. evaluate scores A(QKV) = softmax(QK^T/sqrt(d_k))V\n",
    "        # A_BHTT = Q_BHTK @ K_BHTK.transpose(-2, -1) * (1.0 / math.sqrt(K_BHTK.size(-1)))\n",
    "        # A_BHTT = A_BHTT.masked_fill(self.bias[:, :, :T, :T]==0, float('-inf'))\n",
    "        # A_BHTT = F.softmax(A_BHTT, dim=-1) # todo, when dim=-1?\n",
    "        # S_BHTD = A_BHTT @ V_BHTK\n",
    "        S_BHTD = F.scaled_dot_product_attention(Q_BHTK, K_BHTK, V_BHTK, is_causal=True)\n",
    "\n",
    "        # 3. contextualize the embeddings\n",
    "        S_BTD = S_BHTD.transpose(1, 2).contiguous().view(B, T, D) # performs cat\n",
    "        S_BTD = self.c_proj(S_BTD)\n",
    "\n",
    "        return S_BTD\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D = config.n_embd\n",
    "        self.c_fc = nn.Linear(D, 4*D) # projecting up to extract features from context embeddings\n",
    "        self.gelu = nn.GELU(approximate='tanh') # (Hendrycks et al. https://arxiv.org/abs/1606.08415)\n",
    "        self.c_proj = nn.Linear(4*D, D) # projecting back down to residual pathway\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        X_BT4D = self.c_fc(X_BTD)\n",
    "        X_BT4D = self.gelu(X_BT4D)\n",
    "        X_BTD = self.c_proj(X_BT4D)\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class LayerNorm(nn.Module): # manual inefficient LayerNorm implementation\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward():\n",
    "#         # ...\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D, H = config.n_embd, config.n_head\n",
    "        self.ln_1 = nn.LayerNorm(D)\n",
    "        self.attn = MHA(config)\n",
    "        self.mlp = FFN(config) # .mlp for HF\n",
    "        self.ln_2 = nn.LayerNorm(D)\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        # residuals:\n",
    "        # - (He et al. 2015 https://arxiv.org/abs/1512.03385)\n",
    "        # - (Elhage et al. 2021 https://transformer-circuits.pub/2021/framework/index.html)\n",
    "        X_BTD = X_BTD + self.attn(self.ln_1(X_BTD))\n",
    "        X_BTD = X_BTD + self.mlp(self.ln_2(X_BTD))\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        B, T = config.batch_size, config.block_size\n",
    "        V, D = config.vocab_size, config.n_embd\n",
    "        N, H = config.n_layer, config.n_head\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(V, D), # Wt\n",
    "            wpe = nn.Embedding(T, D), # Wp\n",
    "            h = nn.ModuleList([Block(config) for _ in range(N)]),\n",
    "            ln_f = nn.LayerNorm(D),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(D, V, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight # weight sharing (40m/120m ~30% save)\n",
    "        self.apply(self._init_weights) # weight init (roughly Xavier)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std=0.02 # default std for nn.Linear() and nn.Embedding(). nn.LayerNorm defaults are OK\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'GPT2_SCALE_INIT'):\n",
    "                std = (2 * self.config.n_layer ** -0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias) # instead of default of unit gaussian\n",
    "\n",
    "        if isinstance(module, nn.Linear) or isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std) # ~ 1/sqrt(D={768, 1024, 1280, 1600}) (Xavier init)\n",
    "\n",
    "    def forward(self, X_BT, Y_BT=None): # Some(Y_BT) => training, None => inference\n",
    "        B, T = X_BT.shape\n",
    "        # 1. embedding: BTD\n",
    "        Xtok_BTD = self.transformer.wte(X_BT)\n",
    "        Xpos_TD = self.transformer.wpe(torch.arange(0, T, dtype=torch.long, device=X_BT.device))\n",
    "        X_BTD = Xtok_BTD + Xpos_TD\n",
    "        # 2. N transformer blocks: Nx(BTD -> BTK -> BTD)\n",
    "        for h in self.transformer.h:\n",
    "            X_BTD = h(X_BTD)\n",
    "        # 3. logits: BTD -> BTV\n",
    "        X_BTD = self.transformer.ln_f(X_BTD)\n",
    "        logits_BTV = self.lm_head(X_BTD)\n",
    "        loss = None\n",
    "\n",
    "        if Y_BT is not None:\n",
    "            V = self.config.vocab_size\n",
    "            loss = F.cross_entropy(logits_BTV.view(B*T, V), Y_BT.view(B*T)) # reshape for .cross_entropy()\n",
    "        return logits_BTV, loss\n",
    " \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "\n",
    "\n",
    "\n",
    "        # 1. model init\n",
    "        model_hf, model = GPT2LMHeadModel.from_pretrained(model_type), GPT(GPTConfig(**config_args))\n",
    "        sdhf, sd = model_hf.state_dict(), model.state_dict()\n",
    "        sdhf_keys, sd_keys = sdhf.keys(), sd.keys() # .collect::<Vec<_>>() semantics\n",
    "        # filter\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # 2. copy\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        assert len(sdhf_keys) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sdhf_keys:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sdhf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sdhf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device) # 2x speedup in latency and throughput\n",
    "print(f'model loaded to {device}')\n",
    "model = torch.compile(model)\n",
    "print(f'model compiled to {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 20 batches\n",
      "step: 0, loss: 10.974475860595703, latency(ms): 26646.30, throughput(tok/s): 614.87\n",
      "step: 1, loss: 9.555425643920898, latency(ms): 93.37, throughput(tok/s): 175481.16\n",
      "step: 2, loss: 9.306032180786133, latency(ms): 92.45, throughput(tok/s): 177211.16\n",
      "step: 3, loss: 9.035778999328613, latency(ms): 92.64, throughput(tok/s): 176859.07\n",
      "step: 4, loss: 8.81196403503418, latency(ms): 92.61, throughput(tok/s): 176915.53\n",
      "step: 5, loss: 8.706212997436523, latency(ms): 92.42, throughput(tok/s): 177276.54\n",
      "step: 6, loss: 8.481578826904297, latency(ms): 92.42, throughput(tok/s): 177269.68\n",
      "step: 7, loss: 8.211427688598633, latency(ms): 92.39, throughput(tok/s): 177326.86\n",
      "step: 8, loss: 7.93425989151001, latency(ms): 92.28, throughput(tok/s): 177548.14\n",
      "step: 9, loss: 7.749255657196045, latency(ms): 92.85, throughput(tok/s): 176465.77\n",
      "step: 10, loss: 7.559991836547852, latency(ms): 92.70, throughput(tok/s): 176746.72\n",
      "step: 11, loss: 7.424196720123291, latency(ms): 92.36, throughput(tok/s): 177402.39\n",
      "step: 12, loss: 7.216255187988281, latency(ms): 92.83, throughput(tok/s): 176487.52\n",
      "step: 13, loss: 7.149799346923828, latency(ms): 92.93, throughput(tok/s): 176301.43\n",
      "step: 14, loss: 7.114145755767822, latency(ms): 92.81, throughput(tok/s): 176533.32\n",
      "step: 15, loss: 6.942632675170898, latency(ms): 92.58, throughput(tok/s): 176967.47\n",
      "step: 16, loss: 6.901083946228027, latency(ms): 92.50, throughput(tok/s): 177125.29\n",
      "step: 17, loss: 6.834316253662109, latency(ms): 92.44, throughput(tok/s): 177244.99\n",
      "step: 18, loss: 6.805455207824707, latency(ms): 92.56, throughput(tok/s): 177003.02\n",
      "step: 19, loss: 6.6490936279296875, latency(ms): 92.50, throughput(tok/s): 177117.99\n",
      "step: 20, loss: 6.553936958312988, latency(ms): 92.40, throughput(tok/s): 177315.42\n",
      "step: 21, loss: 6.347126007080078, latency(ms): 92.77, throughput(tok/s): 176617.25\n",
      "step: 22, loss: 6.398042678833008, latency(ms): 93.12, throughput(tok/s): 175943.03\n",
      "step: 23, loss: 6.355079650878906, latency(ms): 92.66, throughput(tok/s): 176810.84\n",
      "step: 24, loss: 6.287437438964844, latency(ms): 92.73, throughput(tok/s): 176684.46\n",
      "step: 25, loss: 6.500025749206543, latency(ms): 92.66, throughput(tok/s): 176813.11\n",
      "step: 26, loss: 6.570192337036133, latency(ms): 92.80, throughput(tok/s): 176553.27\n",
      "step: 27, loss: 6.460057735443115, latency(ms): 92.74, throughput(tok/s): 176660.39\n",
      "step: 28, loss: 6.380187034606934, latency(ms): 92.91, throughput(tok/s): 176344.86\n",
      "step: 29, loss: 6.273728847503662, latency(ms): 92.78, throughput(tok/s): 176595.47\n",
      "step: 30, loss: 6.271113395690918, latency(ms): 92.79, throughput(tok/s): 176580.04\n",
      "step: 31, loss: 6.305844783782959, latency(ms): 93.05, throughput(tok/s): 176072.41\n",
      "step: 32, loss: 6.252793312072754, latency(ms): 92.81, throughput(tok/s): 176531.50\n",
      "step: 33, loss: 6.360513210296631, latency(ms): 92.69, throughput(tok/s): 176760.81\n",
      "step: 34, loss: 6.464410781860352, latency(ms): 93.12, throughput(tok/s): 175951.59\n",
      "step: 35, loss: 6.317892074584961, latency(ms): 92.67, throughput(tok/s): 176796.74\n",
      "step: 36, loss: 6.288850784301758, latency(ms): 92.77, throughput(tok/s): 176604.54\n",
      "step: 37, loss: 6.275681018829346, latency(ms): 93.07, throughput(tok/s): 176039.48\n",
      "step: 38, loss: 6.245368003845215, latency(ms): 92.79, throughput(tok/s): 176568.24\n",
      "step: 39, loss: 6.098971366882324, latency(ms): 93.11, throughput(tok/s): 175965.56\n",
      "step: 40, loss: 6.293036460876465, latency(ms): 93.12, throughput(tok/s): 175938.98\n",
      "step: 41, loss: 6.058076858520508, latency(ms): 92.81, throughput(tok/s): 176527.87\n",
      "step: 42, loss: 6.186049938201904, latency(ms): 92.84, throughput(tok/s): 176473.47\n",
      "step: 43, loss: 6.08989953994751, latency(ms): 93.10, throughput(tok/s): 175973.67\n",
      "step: 44, loss: 6.036923408508301, latency(ms): 92.83, throughput(tok/s): 176485.26\n",
      "step: 45, loss: 6.252217769622803, latency(ms): 93.03, throughput(tok/s): 176121.15\n",
      "step: 46, loss: 6.368053436279297, latency(ms): 93.07, throughput(tok/s): 176037.68\n",
      "step: 47, loss: 6.2393879890441895, latency(ms): 93.08, throughput(tok/s): 176024.15\n",
      "step: 48, loss: 6.168083667755127, latency(ms): 92.99, throughput(tok/s): 176188.43\n",
      "step: 49, loss: 6.079015254974365, latency(ms): 93.31, throughput(tok/s): 175595.51\n",
      "6.079015254974365\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" training loop\n",
    "(Jordan et al. 2024) URL: https://github.com/KellerJordan/modded-nanogpt\n",
    "124M 10x speedup in wallclock time: 45m -> 4m\n",
    "========================================================================\n",
    "- network architecture: rotary embeddings, QK-norm, ReLU^2\n",
    "- muon optimizer\n",
    "- untie head & embedding, FP8 matmul for head, softcap logits (gemma 2)\n",
    "- projection and classification layers init to zero (muP)\n",
    "- skip connections from embedding to every block (and between) via U-net\n",
    "- flexattention with long-short sliding window attention (gemma 2), window size warmup\n",
    "\n",
    "        124M history:\n",
    "        01. 45.0m baseline\n",
    "        02. 31.4m tuned lr, rotary embeddings\n",
    "        03. 24.9m muon optimizer\n",
    "        04. 22.3m muon improvements\n",
    "        05. 15.2m pad embeddings, ReLU^2, zero init, QK-norm\n",
    "        06. 13.1m muon overhead\n",
    "        07. 12.0m pytorch 2.5.0\n",
    "        08. 10.8m united embedding and head\n",
    "        09. 08.2m value and embed skip connections, momentum warmup, logit softcap\n",
    "        10. 07.8m bfloat16 act\n",
    "        11. 07.2m u-net pattern skip connections, double lr\n",
    "        12. 05.0m 1024-ctx dense causal attn -> 64K-ctx flex attention\n",
    "        13. 04.6m attention window warmup\n",
    "        14. 04.4m value embededdings\n",
    "\"\"\"\n",
    "import time\n",
    "import torch\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. dataloader\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        with open('./data/shakespeare.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        encoder = tiktoken.get_encoding('gpt2')\n",
    "        self.tokens = torch.tensor(encoder.encode(text))\n",
    "        self.i = 0\n",
    "\n",
    "        print(f\"loaded {len(self.tokens)} tokens\")\n",
    "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        tokens = self.tokens[self.i:self.i+(B*T+1)]\n",
    "        X_BT, Y_BT = tokens[:-1].view(B,T), tokens[1:].view(B,T)\n",
    "        self.i += B*T\n",
    "        if self.i + (B*T+1) > len(self.tokens):\n",
    "            self.i = 0\n",
    "\n",
    "        return X_BT, Y_BT\n",
    "# print(X_BT)\n",
    "# print(Y_BT)\n",
    "# for b in range(B):\n",
    "#     print('batch', b)\n",
    "#     for t in range(T):\n",
    "#         context = X_BT[b, :t+1]\n",
    "#         target = Y_BT[b, t]\n",
    "#         print('x:', context, '->', 'y:', target)\n",
    "\n",
    "# print(\"==========================================\")\n",
    "\n",
    "# 2. training loop\n",
    "\n",
    "train_loader = DataLoaderLite(B=16, T=1024)\n",
    "torch.set_float32_matmul_precision('high') # highest (fp32) -> high (tf32). 3x instead of advertised 8x speedup (deep learning is memory-bound)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "steps, losses = [], []\n",
    "for step in range(50):\n",
    "    # preprocess\n",
    "    t0 = time.time()\n",
    "    X_BT, Y_BT = train_loader.next_batch()\n",
    "    X_BT, Y_BT = X_BT.to(device), Y_BT.to(device)\n",
    "\n",
    "    # 1. forward\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16): # with ampere and up\n",
    "        logits_BTV, loss = model(X_BT, Y_BT)\n",
    "    # 2. backward\n",
    "    loss.backward()\n",
    "    # 3. step\n",
    "    optimizer.step()\n",
    "\n",
    "    # postprocess\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    latency = (t1-t0)*1000\n",
    "    throughput = (train_loader.B * train_loader.T) / (t1-t0)\n",
    "\n",
    "    steps.append(step)\n",
    "    losses.append(loss.log10().item())\n",
    "    print(f\"step: {step}, loss: {loss.item()}, latency(ms): {latency:.2f}, throughput(tok/s): {throughput:.2f}\")\n",
    "\n",
    "plt.plot(steps, losses)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "H?C,\n",
      "\n",
      "\n",
      " in of and her I' with to him\n",
      "> Hello, I'm a language model,!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " be a to in in,\n",
      " my be hisIO and aH\n",
      "> Hello, I'm a language model,\n",
      " and to theUUS have\n",
      "\n",
      "And. you it no so is is!That, and I\n",
      "> Hello, I'm a language model,I'd?\n",
      "\n",
      "And thou,\n",
      "\n",
      "IUS,I that and? that of;\n",
      " to\n",
      "> Hello, I'm a language model,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " not-\n",
      "\n",
      "\n",
      " you\n",
      "\n",
      " he the this\n",
      " but\n"
     ]
    }
   ],
   "source": [
    "B, T_MAX = 5, 30\n",
    "model.eval()\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "tokens = encoder.encode(\"Hello, I'm a language model,\")\n",
    "tokens_T = torch.tensor(tokens, dtype=torch.long) # # (T,)\n",
    "tokens_BT = tokens_T.unsqueeze(0).repeat(5, 1) # (B,T)\n",
    "X_BT = tokens_BT.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "while X_BT.size(1) < T_MAX:\n",
    "    with torch.no_grad():\n",
    "        logits_BTV, _ = model(X_BT)\n",
    "        logits_BV = logits_BTV[:, -1, :]\n",
    "        probs_ = F.softmax(logits_BV, dim=-1)\n",
    "        topk_probs_, topk_indices_ = torch.topk(probs_, 50, dim=-1)\n",
    "\n",
    "        X_B1 = torch.gather(topk_indices_, -1, torch.multinomial(topk_probs_, 1))\n",
    "        X_BT = torch.cat((X_BT, X_B1), dim=1)\n",
    "\n",
    "for b in range(B):\n",
    "    tokens = X_BT[b, :T_MAX].tolist()\n",
    "    decoded = encoder.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
