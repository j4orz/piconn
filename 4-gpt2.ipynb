{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "model loaded to cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model: gpt2\n",
    "- (Vaswani et al. 2017 https://arxiv.org/abs/1706.03762)\n",
    "- (Radford et al. 2019 https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- (Brown et al. 2020 https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "pre-gpt       ->    gpt2                                 URL\n",
    "-----------------------------------------------------------------------------------------\n",
    "- ReLU        ->    GeLU: (Hendrycks, Gimpel 2016)       https://arxiv.org/abs/1606.08415\n",
    "- BatchNorm   ->    LayerNorm: (Ba et al. 2016)          https://arxiv.org/abs/1607.06450\n",
    "- N/A         ->    Residuals: (He et al. 2015)          https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "\n",
    "Dimension key:\n",
    "\n",
    "# windows\n",
    "B: batch size\n",
    "T: sequence length\n",
    "\n",
    "# input/output\n",
    "V: vocabulary size\n",
    "D: model dimension (n_embd)\n",
    "\n",
    "# attention\n",
    "N: number of transformer blocks (n_layer)\n",
    "H: number of attention heads in a layer (n_head)\n",
    "K: size of each attention key or value (n_k)\n",
    "\"\"\"\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # windows: B, T\n",
    "    batch_size: int = -1   # B\n",
    "    block_size: int = 1024  # T\n",
    "    # input/output:  V, D\n",
    "    vocab_size: int = 50257  # V (256 bytes + 50,000 BPE merges + 1 <|endoftext|> token)\n",
    "    n_embd: int = 768      # D\n",
    "    # attn: NH\n",
    "    n_layer: int = 12      # N\n",
    "    n_head: int = 12       # H\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        T, D, H = config.block_size, config.n_embd, config.n_head\n",
    "        assert D % H == 0\n",
    "\n",
    "        self.H = H\n",
    "\n",
    "        self.c_attn = nn.Linear(D, 3 * D)\n",
    "        self.c_proj = nn.Linear(D, D)\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(T, T)).view(1, 1, T, T)) # tril -> bias for HF\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        B,T,D = X_BTD.shape\n",
    "        H = self.H\n",
    "        # 1. project to learned QKV subspaces Q=WqX, K=WkX, V=WvX\n",
    "        Wq_DK, Wk_DK, Wv_DK = self.c_attn(X_BTD).split(D, dim=2)\n",
    "        Q_BHTK, K_BHTK, V_BHTK = Wq_DK.view(B, T, H, D // H).transpose(1, 2), Wk_DK.view(B, T, H, D // H).transpose(1, 2), Wv_DK.view(B, T, H, D // H).transpose(1, 2)\n",
    "\n",
    "        # 2. evaluate scores A(QKV) = softmax(QK^T/sqrt(d_k))V\n",
    "        A_BHTT = Q_BHTK @ K_BHTK.transpose(-2, -1) * (1.0 / math.sqrt(K_BHTK.size(-1)))\n",
    "        A_BHTT = A_BHTT.masked_fill(self.bias[:, :, :T, :T]==0, float('-inf'))\n",
    "        A_BHTT = F.softmax(A_BHTT, dim=-1) # todo, when dim=-1?\n",
    "\n",
    "        # 3. contextualize the embeddings\n",
    "        S_BHTD = A_BHTT @ V_BHTK\n",
    "        S_BTD = S_BHTD.transpose(1, 2).contiguous().view(B, T, D) # performs cat\n",
    "        S_BTD = self.c_proj(S_BTD)\n",
    "\n",
    "        return S_BTD\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D = config.n_embd\n",
    "        self.c_fc = nn.Linear(D, 4*D) # projecting up to extract features from context embeddings\n",
    "        self.gelu = nn.GELU(approximate='tanh') # (Hendrycks et al. https://arxiv.org/abs/1606.08415)\n",
    "        self.c_proj = nn.Linear(4*D, D) # projecting back down to residual pathway\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        X_BT4D = self.c_fc(X_BTD)\n",
    "        X_BT4D = self.gelu(X_BT4D)\n",
    "        X_BTD = self.c_proj(X_BT4D)\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class LayerNorm(nn.Module): # manual inefficient LayerNorm implementation\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward():\n",
    "#         # ...\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D, H = config.n_embd, config.n_head\n",
    "        self.ln_1 = nn.LayerNorm(D)\n",
    "        self.attn = MHA(config)\n",
    "        self.mlp = FFN(config) # .mlp for HF\n",
    "        self.ln_2 = nn.LayerNorm(D)\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        # residuals:\n",
    "        # - (He et al. 2015 https://arxiv.org/abs/1512.03385)\n",
    "        # - (Elhage et al. 2021 https://transformer-circuits.pub/2021/framework/index.html)\n",
    "        X_BTD = X_BTD + self.attn(self.ln_1(X_BTD))\n",
    "        X_BTD = X_BTD + self.mlp(self.ln_2(X_BTD))\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        B, T = config.batch_size, config.block_size\n",
    "        V, D = config.vocab_size, config.n_embd\n",
    "        N, H = config.n_layer, config.n_head\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(V, D), # Wt\n",
    "            wpe = nn.Embedding(T, D), # Wp\n",
    "            h = nn.ModuleList([Block(config) for _ in range(N)]),\n",
    "            ln_f = nn.LayerNorm(D),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(D, V, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight # weight sharing (40m/120m ~30% save)\n",
    "        self.apply(self._init_weights) # weight init (roughly Xavier)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std=0.02 # default std for nn.Linear() and nn.Embedding(). nn.LayerNorm defaults are OK\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'GPT2_SCALE_INIT'):\n",
    "                std = (2 * self.config.n_layer ** -0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias) # instead of default of unit gaussian\n",
    "\n",
    "        if isinstance(module, nn.Linear) or isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std) # ~ 1/sqrt(D={768, 1024, 1280, 1600}) (Xavier init)\n",
    "\n",
    "    def forward(self, X_BT, Y_BT=None): # Some(Y_BT) => training, None => inference\n",
    "        B, T = X_BT.shape\n",
    "        # 1. embedding: BTD\n",
    "        Xtok_BTD = self.transformer.wte(X_BT)\n",
    "        Xpos_TD = self.transformer.wpe(torch.arange(0, T, dtype=torch.long, device=X_BT.device))\n",
    "        X_BTD = Xtok_BTD + Xpos_TD\n",
    "        # 2. N transformer blocks: Nx(BTD -> BTK -> BTD)\n",
    "        for h in self.transformer.h:\n",
    "            X_BTD = h(X_BTD)\n",
    "        # 3. logits: BTD -> BTV\n",
    "        X_BTD = self.transformer.ln_f(X_BTD)\n",
    "        logits_BTV = self.lm_head(X_BTD)\n",
    "        loss = None\n",
    "\n",
    "        if Y_BT is not None:\n",
    "            V = self.config.vocab_size\n",
    "            loss = F.cross_entropy(logits_BTV.view(B*T, V), Y_BT.view(B*T)) # reshape for .cross_entropy()\n",
    "        return logits_BTV, loss\n",
    " \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "\n",
    "\n",
    "\n",
    "        # 1. model init\n",
    "        model_hf, model = GPT2LMHeadModel.from_pretrained(model_type), GPT(GPTConfig(**config_args))\n",
    "        sdhf, sd = model_hf.state_dict(), model.state_dict()\n",
    "        sdhf_keys, sd_keys = sdhf.keys(), sd.keys() # .collect::<Vec<_>>() semantics\n",
    "        # filter\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # 2. copy\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        assert len(sdhf_keys) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sdhf_keys:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sdhf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sdhf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device)\n",
    "print(f'model loaded to {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 20 batches\n",
      "step: 0, loss: 10.907902717590332, latency(ms): 791.80, throughput(tok/s): 20692.02\n",
      "step: 1, loss: 9.50657844543457, latency(ms): 381.50, throughput(tok/s): 42946.80\n",
      "step: 2, loss: 9.271369934082031, latency(ms): 381.04, throughput(tok/s): 42998.05\n",
      "step: 3, loss: 9.029288291931152, latency(ms): 380.93, throughput(tok/s): 43010.69\n",
      "step: 4, loss: 8.815999984741211, latency(ms): 380.91, throughput(tok/s): 43012.63\n",
      "step: 5, loss: 8.688776969909668, latency(ms): 380.89, throughput(tok/s): 43015.19\n",
      "step: 6, loss: 8.454902648925781, latency(ms): 380.94, throughput(tok/s): 43009.59\n",
      "step: 7, loss: 8.195050239562988, latency(ms): 381.02, throughput(tok/s): 43000.66\n",
      "step: 8, loss: 7.92242431640625, latency(ms): 381.02, throughput(tok/s): 43000.57\n",
      "step: 9, loss: 7.708855628967285, latency(ms): 381.00, throughput(tok/s): 43002.84\n",
      "step: 10, loss: 7.543764591217041, latency(ms): 381.00, throughput(tok/s): 43002.94\n",
      "step: 11, loss: 7.407619476318359, latency(ms): 381.01, throughput(tok/s): 43001.68\n",
      "step: 12, loss: 7.214710235595703, latency(ms): 380.90, throughput(tok/s): 43014.03\n",
      "step: 13, loss: 7.119834899902344, latency(ms): 380.95, throughput(tok/s): 43007.95\n",
      "step: 14, loss: 7.064256191253662, latency(ms): 380.91, throughput(tok/s): 43012.63\n",
      "step: 15, loss: 6.919288635253906, latency(ms): 380.98, throughput(tok/s): 43004.42\n",
      "step: 16, loss: 6.888067722320557, latency(ms): 380.94, throughput(tok/s): 43009.05\n",
      "step: 17, loss: 6.844908714294434, latency(ms): 380.95, throughput(tok/s): 43008.03\n",
      "step: 18, loss: 6.822492599487305, latency(ms): 380.93, throughput(tok/s): 43010.56\n",
      "step: 19, loss: 6.655243873596191, latency(ms): 380.97, throughput(tok/s): 43005.71\n",
      "step: 20, loss: 6.559944152832031, latency(ms): 381.00, throughput(tok/s): 43002.46\n",
      "step: 21, loss: 6.360559940338135, latency(ms): 381.00, throughput(tok/s): 43003.05\n",
      "step: 22, loss: 6.419013977050781, latency(ms): 381.05, throughput(tok/s): 42997.45\n",
      "step: 23, loss: 6.385976791381836, latency(ms): 380.97, throughput(tok/s): 43005.82\n",
      "step: 24, loss: 6.333317756652832, latency(ms): 380.98, throughput(tok/s): 43005.31\n",
      "step: 25, loss: 6.549911022186279, latency(ms): 380.93, throughput(tok/s): 43010.64\n",
      "step: 26, loss: 6.627255916595459, latency(ms): 380.93, throughput(tok/s): 43010.51\n",
      "step: 27, loss: 6.519114017486572, latency(ms): 380.89, throughput(tok/s): 43014.73\n",
      "step: 28, loss: 6.456552982330322, latency(ms): 380.97, throughput(tok/s): 43005.66\n",
      "step: 29, loss: 6.34588623046875, latency(ms): 380.98, throughput(tok/s): 43004.88\n",
      "step: 30, loss: 6.380797386169434, latency(ms): 380.99, throughput(tok/s): 43003.53\n",
      "step: 31, loss: 6.41763973236084, latency(ms): 380.95, throughput(tok/s): 43007.79\n",
      "step: 32, loss: 6.358705043792725, latency(ms): 380.92, throughput(tok/s): 43011.56\n",
      "step: 33, loss: 6.39516544342041, latency(ms): 380.92, throughput(tok/s): 43011.23\n",
      "step: 34, loss: 6.48221492767334, latency(ms): 381.08, throughput(tok/s): 42993.80\n",
      "step: 35, loss: 6.344810962677002, latency(ms): 380.95, throughput(tok/s): 43008.73\n",
      "step: 36, loss: 6.344693183898926, latency(ms): 380.92, throughput(tok/s): 43011.48\n",
      "step: 37, loss: 6.35148286819458, latency(ms): 380.99, throughput(tok/s): 43003.56\n",
      "step: 38, loss: 6.33125638961792, latency(ms): 380.99, throughput(tok/s): 43003.32\n",
      "step: 39, loss: 6.177443027496338, latency(ms): 380.96, throughput(tok/s): 43007.09\n",
      "step: 40, loss: 6.32669734954834, latency(ms): 381.00, throughput(tok/s): 43002.73\n",
      "step: 41, loss: 6.0890936851501465, latency(ms): 380.99, throughput(tok/s): 43003.88\n",
      "step: 42, loss: 6.227444648742676, latency(ms): 381.00, throughput(tok/s): 43002.92\n",
      "step: 43, loss: 6.126490116119385, latency(ms): 381.01, throughput(tok/s): 43001.27\n",
      "step: 44, loss: 6.076045513153076, latency(ms): 381.01, throughput(tok/s): 43000.95\n",
      "step: 45, loss: 6.285703659057617, latency(ms): 381.01, throughput(tok/s): 43001.36\n",
      "step: 46, loss: 6.411420822143555, latency(ms): 381.08, throughput(tok/s): 42993.77\n",
      "step: 47, loss: 6.290205478668213, latency(ms): 381.12, throughput(tok/s): 42989.03\n",
      "step: 48, loss: 6.225763320922852, latency(ms): 381.10, throughput(tok/s): 42991.43\n",
      "step: 49, loss: 6.13716983795166, latency(ms): 381.10, throughput(tok/s): 42991.19\n",
      "6.13716983795166\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" training loop\n",
    "(Jordan et al. 2024) URL: https://github.com/KellerJordan/modded-nanogpt\n",
    "124M 10x speedup: 45m -> 4m\n",
    "========================================================================\n",
    "- network architecture: rotary embeddings, QK-norm, ReLU^2\n",
    "- muon optimizer\n",
    "- untie head & embedding, FP8 matmul for head, softcap logits (gemma 2)\n",
    "- projection and classification layers init to zero (muP)\n",
    "- skip connections from embedding to every block (and between) via U-net\n",
    "- flexattention with long-short sliding window attention (gemma 2), window size warmup\n",
    "\n",
    "        124M history:\n",
    "        01. 45.0m baseline\n",
    "        02. 31.4m tuned lr, rotary embeddings\n",
    "        03. 24.9m muon optimizer\n",
    "        04. 22.3m muon improvements\n",
    "        05. 15.2m pad embeddings, ReLU^2, zero init, QK-norm\n",
    "        06. 13.1m muon overhead\n",
    "        07. 12.0m pytorch 2.5.0\n",
    "        08. 10.8m united embedding and head\n",
    "        09. 08.2m value and embed skip connections, momentum warmup, logit softcap\n",
    "        10. 07.8m bfloat16 act\n",
    "        11. 07.2m u-net pattern skip connections, double lr\n",
    "        12. 05.0m 1024-ctx dense causal attn -> 64K-ctx flex attention\n",
    "        13. 04.6m attention window warmup\n",
    "        14. 04.4m value embededdings\n",
    "\"\"\"\n",
    "import time\n",
    "import torch\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. dataloader\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        with open('./data/shakespeare.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        encoder = tiktoken.get_encoding('gpt2')\n",
    "        self.tokens = torch.tensor(encoder.encode(text))\n",
    "        self.i = 0\n",
    "\n",
    "        print(f\"loaded {len(self.tokens)} tokens\")\n",
    "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        tokens = self.tokens[self.i:self.i+(B*T+1)]\n",
    "        X_BT, Y_BT = tokens[:-1].view(B,T), tokens[1:].view(B,T)\n",
    "        self.i += B*T\n",
    "        if self.i + (B*T+1) > len(self.tokens):\n",
    "            self.i = 0\n",
    "\n",
    "        return X_BT, Y_BT\n",
    "# print(X_BT)\n",
    "# print(Y_BT)\n",
    "# for b in range(B):\n",
    "#     print('batch', b)\n",
    "#     for t in range(T):\n",
    "#         context = X_BT[b, :t+1]\n",
    "#         target = Y_BT[b, t]\n",
    "#         print('x:', context, '->', 'y:', target)\n",
    "\n",
    "# print(\"==========================================\")\n",
    "\n",
    "# 2. training loop\n",
    "\n",
    "train_loader = DataLoaderLite(B=16, T=1024)\n",
    "torch.set_float32_matmul_precision('high') # highest (fp32) -> high (tf32). 3x instead of advertised 8x speedup (deep learning is memory-bound)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "steps, losses = [], []\n",
    "for step in range(50):\n",
    "    # preprocess\n",
    "    t0 = time.time()\n",
    "    X_BT, Y_BT = train_loader.next_batch()\n",
    "    X_BT, Y_BT = X_BT.to(device), Y_BT.to(device)\n",
    "\n",
    "    # 1. forward\n",
    "    optimizer.zero_grad()\n",
    "    logits_BTV, loss = model(X_BT, Y_BT)\n",
    "    # 2. backward\n",
    "    loss.backward()\n",
    "    # 3. step\n",
    "    optimizer.step()\n",
    "\n",
    "    # postprocess\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    latency = (t1-t0)*1000\n",
    "    throughput = (train_loader.B * train_loader.T) / (t1-t0)\n",
    "\n",
    "    steps.append(step)\n",
    "    losses.append(loss.log10().item())\n",
    "    print(f\"step: {step}, loss: {loss.item()}, latency(ms): {latency:.2f}, throughput(tok/s): {throughput:.2f}\")\n",
    "\n",
    "plt.plot(steps, losses)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model,?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " he but'd,\n",
      "\n",
      "\n",
      "'s of you thy of as he\n",
      "D\n",
      "> Hello, I'm a language model, not to,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      "\n",
      "\n",
      "That not are\n",
      "> Hello, I'm a language model, to: to with all be be, with:\n",
      "!\n",
      "KINGU not!\n",
      " the,\n",
      "\n",
      "\n",
      "> Hello, I'm a language model,; he a.\n",
      " and shall:\n",
      "\n",
      "And be,I your I and all,\n",
      "I his\n",
      "> Hello, I'm a language model, to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " him all,\n",
      "\n",
      "?\n",
      "\n",
      "IO of as, my\n"
     ]
    }
   ],
   "source": [
    "B, T_MAX = 5, 30\n",
    "model.eval()\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "tokens = encoder.encode(\"Hello, I'm a language model,\")\n",
    "tokens_T = torch.tensor(tokens, dtype=torch.long) # # (T,)\n",
    "tokens_BT = tokens_T.unsqueeze(0).repeat(5, 1) # (B,T)\n",
    "X_BT = tokens_BT.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "while X_BT.size(1) < T_MAX:\n",
    "    with torch.no_grad():\n",
    "        logits_BTV, _ = model(X_BT)\n",
    "        logits_BV = logits_BTV[:, -1, :]\n",
    "        probs_ = F.softmax(logits_BV, dim=-1)\n",
    "        topk_probs_, topk_indices_ = torch.topk(probs_, 50, dim=-1)\n",
    "\n",
    "        X_B1 = torch.gather(topk_indices_, -1, torch.multinomial(topk_probs_, 1))\n",
    "        X_BT = torch.cat((X_BT, X_B1), dim=1)\n",
    "\n",
    "for b in range(B):\n",
    "    tokens = X_BT[b, :T_MAX].tolist()\n",
    "    decoded = encoder.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
