{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "model loaded to cuda\n",
      "model compiled to cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model: gpt2\n",
    "- (Vaswani et al. 2017 https://arxiv.org/abs/1706.03762)\n",
    "- (Radford et al. 2019 https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- (Brown et al. 2020 https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "pre-gpt       ->    gpt2                                 URL\n",
    "-----------------------------------------------------------------------------------------\n",
    "- ReLU        ->    GeLU: (Hendrycks, Gimpel 2016)       https://arxiv.org/abs/1606.08415\n",
    "- BatchNorm   ->    LayerNorm: (Ba et al. 2016)          https://arxiv.org/abs/1607.06450\n",
    "- N/A         ->    Residuals: (He et al. 2015)          https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "\n",
    "Dimension key:\n",
    "\n",
    "# windows\n",
    "B: batch size\n",
    "T: sequence length\n",
    "\n",
    "# input/output\n",
    "V: vocabulary size\n",
    "D: model dimension (n_embd)\n",
    "\n",
    "# attention\n",
    "N: number of transformer blocks (n_layer)\n",
    "H: number of attention heads in a layer (n_head)\n",
    "K: size of each attention key or value (n_k)\n",
    "\"\"\"\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device {device}\")\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # windows: B, T\n",
    "    batch_size: int = -1   # B\n",
    "    block_size: int = 1024  # T\n",
    "    # input/output:  V, D\n",
    "    vocab_size: int = 50257  # V (256 bytes + 50,000 BPE merges + 1 <|endoftext|> token)\n",
    "    n_embd: int = 768      # D\n",
    "    # attn: NH\n",
    "    n_layer: int = 12      # N\n",
    "    n_head: int = 12       # H\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        T, D, H = config.block_size, config.n_embd, config.n_head\n",
    "        assert D % H == 0\n",
    "\n",
    "        self.H = H\n",
    "\n",
    "        self.c_attn = nn.Linear(D, 3 * D)\n",
    "        self.c_proj = nn.Linear(D, D)\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(T, T)).view(1, 1, T, T)) # tril -> bias for HF\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        B,T,D = X_BTD.shape\n",
    "        H = self.H\n",
    "        # 1. project to learned QKV subspaces Q=WqX, K=WkX, V=WvX\n",
    "        Wq_DK, Wk_DK, Wv_DK = self.c_attn(X_BTD).split(D, dim=2)\n",
    "        Q_BHTK, K_BHTK, V_BHTK = Wq_DK.view(B, T, H, D // H).transpose(1, 2), Wk_DK.view(B, T, H, D // H).transpose(1, 2), Wv_DK.view(B, T, H, D // H).transpose(1, 2)\n",
    "\n",
    "        # 2. evaluate scores A(QKV) = softmax(QK^T/sqrt(d_k))V\n",
    "        # A_BHTT = Q_BHTK @ K_BHTK.transpose(-2, -1) * (1.0 / math.sqrt(K_BHTK.size(-1)))\n",
    "        # A_BHTT = A_BHTT.masked_fill(self.bias[:, :, :T, :T]==0, float('-inf'))\n",
    "        # A_BHTT = F.softmax(A_BHTT, dim=-1) # todo, when dim=-1?\n",
    "        # S_BHTD = A_BHTT @ V_BHTK\n",
    "        S_BHTD = F.scaled_dot_product_attention(Q_BHTK, K_BHTK, V_BHTK, is_causal=True)\n",
    "\n",
    "        # 3. contextualize the embeddings\n",
    "        S_BTD = S_BHTD.transpose(1, 2).contiguous().view(B, T, D) # performs cat\n",
    "        S_BTD = self.c_proj(S_BTD)\n",
    "\n",
    "        return S_BTD\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D = config.n_embd\n",
    "        self.c_fc = nn.Linear(D, 4*D) # projecting up to extract features from context embeddings\n",
    "        self.gelu = nn.GELU(approximate='tanh') # (Hendrycks et al. https://arxiv.org/abs/1606.08415)\n",
    "        self.c_proj = nn.Linear(4*D, D) # projecting back down to residual pathway\n",
    "        self.c_proj.GPT2_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        X_BT4D = self.c_fc(X_BTD)\n",
    "        X_BT4D = self.gelu(X_BT4D)\n",
    "        X_BTD = self.c_proj(X_BT4D)\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class LayerNorm(nn.Module): # manual inefficient LayerNorm implementation\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward():\n",
    "#         # ...\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        D, H = config.n_embd, config.n_head\n",
    "        self.ln_1 = nn.LayerNorm(D)\n",
    "        self.attn = MHA(config)\n",
    "        self.mlp = FFN(config) # .mlp for HF\n",
    "        self.ln_2 = nn.LayerNorm(D)\n",
    "\n",
    "    def forward(self, X_BTD):\n",
    "        # residuals:\n",
    "        # - (He et al. 2015 https://arxiv.org/abs/1512.03385)\n",
    "        # - (Elhage et al. 2021 https://transformer-circuits.pub/2021/framework/index.html)\n",
    "        X_BTD = X_BTD + self.attn(self.ln_1(X_BTD))\n",
    "        X_BTD = X_BTD + self.mlp(self.ln_2(X_BTD))\n",
    "        return X_BTD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        B, T = config.batch_size, config.block_size\n",
    "        V, D = config.vocab_size, config.n_embd\n",
    "        N, H = config.n_layer, config.n_head\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(V, D), # Wt\n",
    "            wpe = nn.Embedding(T, D), # Wp\n",
    "            h = nn.ModuleList([Block(config) for _ in range(N)]),\n",
    "            ln_f = nn.LayerNorm(D),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(D, V, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight # weight sharing (40m/120m ~30% save)\n",
    "        self.apply(self._init_weights) # weight init (roughly Xavier)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std=0.02 # default std for nn.Linear() and nn.Embedding(). nn.LayerNorm defaults are OK\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'GPT2_SCALE_INIT'):\n",
    "                std = (2 * self.config.n_layer ** -0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias) # instead of default of unit gaussian\n",
    "\n",
    "        if isinstance(module, nn.Linear) or isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std) # ~ 1/sqrt(D={768, 1024, 1280, 1600}) (Xavier init)\n",
    "\n",
    "    def forward(self, X_BT, Y_BT=None): # Some(Y_BT) => training, None => inference\n",
    "        B, T = X_BT.shape\n",
    "        # 1. embedding: BTD\n",
    "        Xtok_BTD = self.transformer.wte(X_BT)\n",
    "        Xpos_TD = self.transformer.wpe(torch.arange(0, T, dtype=torch.long, device=X_BT.device))\n",
    "        X_BTD = Xtok_BTD + Xpos_TD\n",
    "        # 2. N transformer blocks: Nx(BTD -> BTK -> BTD)\n",
    "        for h in self.transformer.h:\n",
    "            X_BTD = h(X_BTD)\n",
    "        # 3. logits: BTD -> BTV\n",
    "        X_BTD = self.transformer.ln_f(X_BTD)\n",
    "        logits_BTV = self.lm_head(X_BTD)\n",
    "        loss = None\n",
    "\n",
    "        if Y_BT is not None:\n",
    "            V = self.config.vocab_size\n",
    "            loss = F.cross_entropy(logits_BTV.view(B*T, V), Y_BT.view(B*T)) # reshape for .cross_entropy()\n",
    "        return logits_BTV, loss\n",
    " \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "\n",
    "\n",
    "\n",
    "        # 1. model init\n",
    "        model_hf, model = GPT2LMHeadModel.from_pretrained(model_type), GPT(GPTConfig(**config_args))\n",
    "        sdhf, sd = model_hf.state_dict(), model.state_dict()\n",
    "        sdhf_keys, sd_keys = sdhf.keys(), sd.keys() # .collect::<Vec<_>>() semantics\n",
    "        # filter\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sdhf_keys = [k for k in sdhf_keys if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # 2. copy\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        assert len(sdhf_keys) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sdhf_keys:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sdhf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sdhf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sdhf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device) # 2x speedup in latency and throughput\n",
    "print(f'model loaded to {device}')\n",
    "model = torch.compile(model)\n",
    "print(f'model compiled to {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 20 batches\n",
      "step: 0, loss: 10.907672882080078, latency(ms): 27309.85, throughput(tok/s): 599.93\n",
      "step: 1, loss: 9.505921363830566, latency(ms): 96.14, throughput(tok/s): 170414.92\n",
      "step: 2, loss: 9.270709991455078, latency(ms): 94.99, throughput(tok/s): 172473.93\n",
      "step: 3, loss: 9.03009033203125, latency(ms): 95.41, throughput(tok/s): 171729.14\n",
      "step: 4, loss: 8.816146850585938, latency(ms): 95.30, throughput(tok/s): 171928.93\n",
      "step: 5, loss: 8.688261985778809, latency(ms): 95.16, throughput(tok/s): 172171.01\n",
      "step: 6, loss: 8.454371452331543, latency(ms): 95.39, throughput(tok/s): 171765.20\n",
      "step: 7, loss: 8.194618225097656, latency(ms): 95.42, throughput(tok/s): 171704.68\n",
      "step: 8, loss: 7.9224724769592285, latency(ms): 95.54, throughput(tok/s): 171492.58\n",
      "step: 9, loss: 7.70988130569458, latency(ms): 95.41, throughput(tok/s): 171728.28\n",
      "step: 10, loss: 7.542749881744385, latency(ms): 95.35, throughput(tok/s): 171828.76\n",
      "step: 11, loss: 7.407326698303223, latency(ms): 95.27, throughput(tok/s): 171968.51\n",
      "step: 12, loss: 7.213508605957031, latency(ms): 95.35, throughput(tok/s): 171825.32\n",
      "step: 13, loss: 7.119558811187744, latency(ms): 95.32, throughput(tok/s): 171876.90\n",
      "step: 14, loss: 7.064239978790283, latency(ms): 95.47, throughput(tok/s): 171615.06\n",
      "step: 15, loss: 6.91926383972168, latency(ms): 95.12, throughput(tok/s): 172249.12\n",
      "step: 16, loss: 6.88823127746582, latency(ms): 95.83, throughput(tok/s): 170976.72\n",
      "step: 17, loss: 6.844593524932861, latency(ms): 95.26, throughput(tok/s): 171998.21\n",
      "step: 18, loss: 6.822330474853516, latency(ms): 95.13, throughput(tok/s): 172220.20\n",
      "step: 19, loss: 6.6548004150390625, latency(ms): 95.86, throughput(tok/s): 170921.01\n",
      "step: 20, loss: 6.559345245361328, latency(ms): 95.37, throughput(tok/s): 171789.67\n",
      "step: 21, loss: 6.359764099121094, latency(ms): 95.02, throughput(tok/s): 172431.95\n",
      "step: 22, loss: 6.418984413146973, latency(ms): 95.35, throughput(tok/s): 171827.90\n",
      "step: 23, loss: 6.3860063552856445, latency(ms): 95.57, throughput(tok/s): 171433.54\n",
      "step: 24, loss: 6.333331108093262, latency(ms): 95.28, throughput(tok/s): 171949.15\n",
      "step: 25, loss: 6.549860000610352, latency(ms): 95.19, throughput(tok/s): 172122.28\n",
      "step: 26, loss: 6.627477645874023, latency(ms): 95.17, throughput(tok/s): 172162.38\n",
      "step: 27, loss: 6.518614292144775, latency(ms): 95.56, throughput(tok/s): 171444.23\n",
      "step: 28, loss: 6.456745147705078, latency(ms): 95.68, throughput(tok/s): 171234.90\n",
      "step: 29, loss: 6.345125198364258, latency(ms): 95.54, throughput(tok/s): 171491.72\n",
      "step: 30, loss: 6.380334854125977, latency(ms): 95.55, throughput(tok/s): 171469.90\n",
      "step: 31, loss: 6.417691230773926, latency(ms): 95.84, throughput(tok/s): 170943.97\n",
      "step: 32, loss: 6.358306884765625, latency(ms): 95.63, throughput(tok/s): 171334.80\n",
      "step: 33, loss: 6.394742012023926, latency(ms): 95.29, throughput(tok/s): 171940.11\n",
      "step: 34, loss: 6.481725692749023, latency(ms): 95.71, throughput(tok/s): 171189.68\n",
      "step: 35, loss: 6.344490051269531, latency(ms): 95.15, throughput(tok/s): 172185.68\n",
      "step: 36, loss: 6.34416389465332, latency(ms): 95.59, throughput(tok/s): 171395.48\n",
      "step: 37, loss: 6.350764274597168, latency(ms): 95.90, throughput(tok/s): 170848.35\n",
      "step: 38, loss: 6.330548286437988, latency(ms): 95.60, throughput(tok/s): 171377.96\n",
      "step: 39, loss: 6.176718711853027, latency(ms): 95.60, throughput(tok/s): 171372.40\n",
      "step: 40, loss: 6.326343059539795, latency(ms): 95.87, throughput(tok/s): 170890.83\n",
      "step: 41, loss: 6.0890655517578125, latency(ms): 95.56, throughput(tok/s): 171449.79\n",
      "step: 42, loss: 6.227752685546875, latency(ms): 95.58, throughput(tok/s): 171416.01\n",
      "step: 43, loss: 6.126347541809082, latency(ms): 95.84, throughput(tok/s): 170946.95\n",
      "step: 44, loss: 6.076136112213135, latency(ms): 95.60, throughput(tok/s): 171374.11\n",
      "step: 45, loss: 6.28541374206543, latency(ms): 95.42, throughput(tok/s): 171696.96\n",
      "step: 46, loss: 6.411332607269287, latency(ms): 95.82, throughput(tok/s): 170990.76\n",
      "step: 47, loss: 6.290111064910889, latency(ms): 95.50, throughput(tok/s): 171567.08\n",
      "step: 48, loss: 6.225347518920898, latency(ms): 95.60, throughput(tok/s): 171383.94\n",
      "step: 49, loss: 6.136920928955078, latency(ms): 95.83, throughput(tok/s): 170963.11\n",
      "6.136920928955078\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" training loop\n",
    "(Jordan et al. 2024) URL: https://github.com/KellerJordan/modded-nanogpt\n",
    "124M 10x speedup in wallclock time: 45m -> 4m\n",
    "========================================================================\n",
    "- network architecture: rotary embeddings, QK-norm, ReLU^2\n",
    "- muon optimizer\n",
    "- untie head & embedding, FP8 matmul for head, softcap logits (gemma 2)\n",
    "- projection and classification layers init to zero (muP)\n",
    "- skip connections from embedding to every block (and between) via U-net\n",
    "- flexattention with long-short sliding window attention (gemma 2), window size warmup\n",
    "\n",
    "        124M history:\n",
    "        01. 45.0m baseline\n",
    "        02. 31.4m tuned lr, rotary embeddings\n",
    "        03. 24.9m muon optimizer\n",
    "        04. 22.3m muon improvements\n",
    "        05. 15.2m pad embeddings, ReLU^2, zero init, QK-norm\n",
    "        06. 13.1m muon overhead\n",
    "        07. 12.0m pytorch 2.5.0\n",
    "        08. 10.8m united embedding and head\n",
    "        09. 08.2m value and embed skip connections, momentum warmup, logit softcap\n",
    "        10. 07.8m bfloat16 act\n",
    "        11. 07.2m u-net pattern skip connections, double lr\n",
    "        12. 05.0m 1024-ctx dense causal attn -> 64K-ctx flex attention\n",
    "        13. 04.6m attention window warmup\n",
    "        14. 04.4m value embededdings\n",
    "\"\"\"\n",
    "import time\n",
    "import torch\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. dataloader\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        with open('./data/shakespeare.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        encoder = tiktoken.get_encoding('gpt2')\n",
    "        self.tokens = torch.tensor(encoder.encode(text))\n",
    "        self.i = 0\n",
    "\n",
    "        print(f\"loaded {len(self.tokens)} tokens\")\n",
    "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        tokens = self.tokens[self.i:self.i+(B*T+1)]\n",
    "        X_BT, Y_BT = tokens[:-1].view(B,T), tokens[1:].view(B,T)\n",
    "        self.i += B*T\n",
    "        if self.i + (B*T+1) > len(self.tokens):\n",
    "            self.i = 0\n",
    "\n",
    "        return X_BT, Y_BT\n",
    "# print(X_BT)\n",
    "# print(Y_BT)\n",
    "# for b in range(B):\n",
    "#     print('batch', b)\n",
    "#     for t in range(T):\n",
    "#         context = X_BT[b, :t+1]\n",
    "#         target = Y_BT[b, t]\n",
    "#         print('x:', context, '->', 'y:', target)\n",
    "\n",
    "# print(\"==========================================\")\n",
    "\n",
    "# 2. training loop\n",
    "\n",
    "train_loader = DataLoaderLite(B=16, T=1024)\n",
    "torch.set_float32_matmul_precision('high') # highest (fp32) -> high (tf32). 3x instead of advertised 8x speedup (deep learning is memory-bound)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "steps, losses = [], []\n",
    "for step in range(50):\n",
    "    # preprocess\n",
    "    t0 = time.time()\n",
    "    X_BT, Y_BT = train_loader.next_batch()\n",
    "    X_BT, Y_BT = X_BT.to(device), Y_BT.to(device)\n",
    "\n",
    "    # 1. forward\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16): # with ampere and up\n",
    "        logits_BTV, loss = model(X_BT, Y_BT)\n",
    "    # 2. backward\n",
    "    loss.backward()\n",
    "    # 3. step\n",
    "    optimizer.step()\n",
    "\n",
    "    # postprocess\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    latency = (t1-t0)*1000\n",
    "    throughput = (train_loader.B * train_loader.T) / (t1-t0)\n",
    "\n",
    "    steps.append(step)\n",
    "    losses.append(loss.log10().item())\n",
    "    print(f\"step: {step}, loss: {loss.item()}, latency(ms): {latency:.2f}, throughput(tok/s): {throughput:.2f}\")\n",
    "\n",
    "plt.plot(steps, losses)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model,?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " he but'd,\n",
      "\n",
      "\n",
      "'s of you thy of as this\n",
      " in\n",
      "> Hello, I'm a language model, not to,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " beI of a?\n",
      "\n",
      "US have,\n",
      ";\n",
      " we\n",
      "> Hello, I'm a language model, to: to with all be be, with:\n",
      "DIO noEN not!\n",
      " you,\n",
      "\n",
      "\n",
      "> Hello, I'm a language model,; he a.\n",
      " and shall:\n",
      "\n",
      "And be,I it my and all,\n",
      "IIO\n",
      "> Hello, I'm a language model, to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "As all,\n",
      "\n",
      "?\n",
      "\n",
      " it to as, my\n"
     ]
    }
   ],
   "source": [
    "B, T_MAX = 5, 30\n",
    "model.eval()\n",
    "\n",
    "import tiktoken\n",
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "tokens = encoder.encode(\"Hello, I'm a language model,\")\n",
    "tokens_T = torch.tensor(tokens, dtype=torch.long) # # (T,)\n",
    "tokens_BT = tokens_T.unsqueeze(0).repeat(5, 1) # (B,T)\n",
    "X_BT = tokens_BT.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "while X_BT.size(1) < T_MAX:\n",
    "    with torch.no_grad():\n",
    "        logits_BTV, _ = model(X_BT)\n",
    "        logits_BV = logits_BTV[:, -1, :]\n",
    "        probs_ = F.softmax(logits_BV, dim=-1)\n",
    "        topk_probs_, topk_indices_ = torch.topk(probs_, 50, dim=-1)\n",
    "\n",
    "        X_B1 = torch.gather(topk_indices_, -1, torch.multinomial(topk_probs_, 1))\n",
    "        X_BT = torch.cat((X_BT, X_B1), dim=1)\n",
    "\n",
    "for b in range(B):\n",
    "    tokens = X_BT[b, :T_MAX].tolist()\n",
    "    decoded = encoder.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
